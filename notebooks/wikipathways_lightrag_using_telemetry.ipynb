{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiPathways - Using LightRAG to understand disease pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_QUERY=\"What are the core pathways for this disease?\"\n",
    "\n",
    "SRC_FILE_URL = \"https://www.wikipathways.org/wikipathways-assets/pathways/WP4255/WP4255.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ipywidgets lightrag-hku openai aioboto3 tiktoken nano_vectordb\n",
    "%pip install -q arize-phoenix-otel openinference-instrumentation-openai openai 'httpx<0.28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define configuration constants\n",
    "DATA_DIR = Path(\"../data\")  # Base data directory\n",
    "INTERIM_DIR = DATA_DIR / \"interim\"  # Interim data directory\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"  # Processed data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "# Define URL and local file path\n",
    "SRC_FILE_URL = \"https://www.wikipathways.org/wikipathways-assets/pathways/WP4255/WP4255.json\"\n",
    "file_name = SRC_FILE_URL.split(\"/\")[-1].replace(\".\", \"_\").lower()\n",
    "\n",
    "WORKING_DIR = INTERIM_DIR / file_name\n",
    "\n",
    "# Replace operation: ensure WORKING_DIR is fresh\n",
    "if os.path.exists(WORKING_DIR):\n",
    "    shutil.rmtree(WORKING_DIR)  # Remove the existing directory and its contents\n",
    "os.mkdir(WORKING_DIR)           # Create a new, empty directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and save the file\n",
    "response = requests.get(SRC_FILE_URL)\n",
    "response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "local_file_path = WORKING_DIR / f\"{file_name}.txt\"\n",
    "local_file_path.write_text(response.text)\n",
    "\n",
    "# Define file paths\n",
    "GRAPHML_FILE = WORKING_DIR / f\"graph_chunk_entity_relation.graphml\"\n",
    "PYVIS_HTML_FILE = PROCESSED_DIR / f\"{file_name}.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arize Phoenix - telemetry\n",
    "\n",
    "- UI endpoint:  http://localhost:6006\n",
    "- NOTE:  the Docker container will be removed when you shut down the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more information refer to https://docs.arize.com/phoenix/tracing/integrations-tracing/autogen-support#docker\n",
    "# !docker run -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Run the Docker container without interactive mode\n",
    "subprocess.Popen([\n",
    "    \"docker\", \"run\", \"-p\", \"6006:6006\", \"-p\", \"4317:4317\",\n",
    "    \"--rm\", \"arizephoenix/phoenix:latest\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "# defaults to endpoint=\"http://localhost:4317\"\n",
    "tracer_provider = register(\n",
    "  project_name=\"lightrag-openai\", # Default is 'default'\n",
    "  endpoint=\"http://localhost:4317\",  # Sends traces using gRPC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Graph\n",
    "\n",
    "- Initialize LightRAG and OpenAI connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm import gpt_4o_mini_complete\n",
    "import nano_vectordb\n",
    "\n",
    "# next two lines are required if running in a jupyter notebook to handle the async nature of rag.insert()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=gpt_4o_mini_complete\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(local_file_path) as f:\n",
    "    rag.insert(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hybrid search\n",
    "print(\"\\n## APPROACH 4\\n\")\n",
    "print(rag.query(RAG_QUERY, param=QueryParam(mode=\"hybrid\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Graph\n",
    "\n",
    "- graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def create_interactive_visualization(graphml_file, output_file):\n",
    "    # Load the GraphML file\n",
    "    G = nx.read_graphml(graphml_file)\n",
    "    \n",
    "    # Create Pyvis network\n",
    "    net = Network(height='900px', width='100%', bgcolor='#ffffff', \n",
    "                 font_color='black', notebook=False)\n",
    "    \n",
    "    # Define color scheme for entity types\n",
    "    entity_colors = {\n",
    "        'PERSON': '#e41a1c',              # Bright red\n",
    "        'ORGANIZATION': '#377eb8',        # Blue\n",
    "        'GEO': '#4daf4a',                 # Green\n",
    "        'EVENT': '#984ea3',               # Purple\n",
    "        'CONCEPT': '#ff7f00',             # Orange\n",
    "        'TECHNOLOGY': '#a65628',          # Brown\n",
    "        'CATEGORY': '#f781bf',            # Pink\n",
    "        'BIOLOGICAL PROCESS': '#ff1493', # Deep Pink\n",
    "        'CELLULAR COMPONENT': '#8a2be2', # Blue Violet\n",
    "        'DATA NODE': '#00ced1',           # Dark Turquoise\n",
    "        'ENTITY': '#4682b4',              # Steel Blue\n",
    "        'GENE': '#32cd32',                # Lime Green\n",
    "        'GENEPRODUCT': '#adff2f',         # Green Yellow\n",
    "        'IDENTIFIER': '#ff6347',          # Tomato\n",
    "        'LEGEND': '#daa520',              # Goldenrod\n",
    "        'METABOLITE': '#20b2aa',          # Light Sea Green\n",
    "        'PATHWAY': '#ff4500',             # Orange Red\n",
    "        'PROTEIN': '#6a5acd',             # Slate Blue\n",
    "        'STATE': '#7fffd4',               # Aquamarine\n",
    "        'TERM': '#bdb76b',                # Dark Khaki\n",
    "        'UNKNOWN': '#808080'              # Dark Gray\n",
    "    }\n",
    "    \n",
    "    # Add nodes with colors before adding edges\n",
    "    for node_id, node_data in G.nodes(data=True):\n",
    "        # Get entity type (removing quotes if present)\n",
    "        entity_type = node_data.get('entity_type', 'UNKNOWN').replace('\"', '')\n",
    "        color = entity_colors.get(entity_type, '#808080')\n",
    "        \n",
    "        # Create hover text\n",
    "        hover_info = f\"\"\"\n",
    "        Entity: {node_id}\n",
    "        Type: {entity_type}\n",
    "        Description: {node_data.get('description', 'N/A')}\n",
    "        Source ID: {node_data.get('source_id', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add node with properties\n",
    "        net.add_node(node_id, \n",
    "                    title=hover_info,\n",
    "                    color=color,\n",
    "                    size=30)\n",
    "\n",
    "    # Add edges\n",
    "    for source, target, edge_data in G.edges(data=True):\n",
    "        weight = edge_data.get('weight', 1)\n",
    "        description = edge_data.get('description', '')\n",
    "        \n",
    "        hover_info = f\"\"\"\n",
    "        Weight: {weight}\n",
    "        Description: {description}\n",
    "        Keywords: {edge_data.get('keywords', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        net.add_edge(source, target,\n",
    "                    title=hover_info,\n",
    "                    width=float(weight),\n",
    "                    color={'color': '#666666', 'highlight': '#ff0000'})\n",
    "\n",
    "    # Rest of your physics and legend code remains the same\n",
    "    physics_options = {\n",
    "        \"physics\": {\n",
    "            \"forceAtlas2Based\": {\n",
    "                \"gravitationalConstant\": -100,\n",
    "                \"centralGravity\": 0.01,\n",
    "                \"springLength\": 200,\n",
    "                \"springConstant\": 0.08,\n",
    "                \"damping\": 0.4,\n",
    "                \"avoidOverlap\": 1\n",
    "            },\n",
    "            \"solver\": \"forceAtlas2Based\",\n",
    "            \"stabilization\": {\n",
    "                \"enabled\": True,\n",
    "                \"iterations\": 1000,\n",
    "                \"updateInterval\": 25\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    net.set_options(json.dumps(physics_options))\n",
    "    \n",
    "    # Save and add legend\n",
    "    net.write_html(output_file)\n",
    "    \n",
    "    # Add legend HTML\n",
    "    legend_html = \"\"\"\n",
    "    <div style=\"position: absolute; top: 10px; left: 10px; background-color: rgba(255, 255, 255, 0.9); \n",
    "                padding: 10px; border-radius: 5px; border: 1px solid #ccc;\">\n",
    "        <h3>Entity Types</h3>\n",
    "        <ul style=\"list-style-type: none; padding: 0;\">\n",
    "    \"\"\"\n",
    "    \n",
    "    for entity_type, color in entity_colors.items():\n",
    "        legend_html += f\"\"\"\n",
    "            <li style=\"margin: 5px 0;\">\n",
    "                <span style=\"display: inline-block; width: 20px; height: 20px; \n",
    "                           background-color: {color}; border-radius: 50%; margin-right: 5px;\"></span>\n",
    "                {entity_type}\n",
    "            </li>\n",
    "        \"\"\"\n",
    "    \n",
    "    legend_html += \"\"\"\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    content = content.replace('</body>', f'{legend_html}</body>')\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Visualization\n",
    "create_interactive_visualization(GRAPHML_FILE, str(PYVIS_HTML_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Telemetry data\n",
    "\n",
    "- Access the Arize Phoenix UI at [http://localhost:6006](http://localhost:6006)\n",
    "- both LLM inference and embedding telemetry information is captured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç LightRAG Validation with Arize Phoenix\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook provides one approach for validating and monitoring LightRAG's interaction with LLMs and embedding models -- leveraging [Arize Phoenix](https://docs.arize.com/phoenix/tracing/llm-traces-1) it provides insight into what is a very complex data ingestion pipeline.\n",
    "\n",
    "It will also make the concepts covered in the LightRAG paper more tangible.\n",
    "\n",
    "### Purpose\n",
    "- **System Monitoring**: Validate LightRAG's integration with telemetry pipelines to ensure robust tracking of model inference and embedding use.\n",
    "- **Performance Tuning**: Identify bottlenecks and optimize configurations using insights from telemetry data.\n",
    "- **Proactive Debugging**: Quickly detect and resolve anomalies through real-time analysis.\n",
    "\n",
    "### Key Features\n",
    "- **Dockerized Deployment**: Simplifies setup with preconfigured Docker containers for Arize Phoenix.\n",
    "- **Telemetry Integration**: Supports integration with external systems through use of OpenTelemetry standard to provide detailed system traces.\n",
    "- **Customizable Dashboards**: Enables interactive exploration of model metrics and error logs.\n",
    "\n",
    "### Usage Instructions\n",
    "1. **Setup**: \n",
    "    - Install required dependencies:\n",
    "      ```bash\n",
    "      pip install arize-phoenix-otel\n",
    "      ```\n",
    "    - Run the Docker container for Arize Phoenix:\n",
    "      ```bash\n",
    "      docker run -p 6006:6006 -p 4317:4317 --rm arizephoenix/phoenix:latest\n",
    "      ```\n",
    "\n",
    "2. **Execute the Notebook**: Follow the provided steps in the notebook to validate your LightRAG setup against telemetry data.\n",
    "\n",
    "3. **Explore Metrics**:\n",
    "    - Access the Phoenix UI at [http://localhost:6006](http://localhost:6006).\n",
    "    - Analyze detailed traces, latencies, and throughput metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
