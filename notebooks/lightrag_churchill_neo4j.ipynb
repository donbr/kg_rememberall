{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç LightRAG Validation with Arize Phoenix\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook provides one approach for validating and monitoring LightRAG's interaction with LLMs and embedding models -- leveraging [Arize Phoenix](https://docs.arize.com/phoenix/tracing/llm-traces-1) it provides insight into what is a very complex data ingestion pipeline.\n",
    "\n",
    "It will also make the concepts covered in the LightRAG paper more tangible.\n",
    "\n",
    "### Purpose\n",
    "- **System Monitoring**: Validate LightRAG's integration with telemetry pipelines to ensure robust tracking of model inference and embedding use.\n",
    "- **Performance Tuning**: Identify bottlenecks and optimize configurations using insights from telemetry data.\n",
    "- **Proactive Debugging**: Quickly detect and resolve anomalies through real-time analysis.\n",
    "\n",
    "### Key Features\n",
    "- **Dockerized Deployment**: Simplifies setup with preconfigured Docker containers for Arize Phoenix.\n",
    "- **Telemetry Integration**: Supports integration with external systems through use of OpenTelemetry standard to provide detailed system traces.\n",
    "- **Customizable Dashboards**: Enables interactive exploration of model metrics and error logs.\n",
    "\n",
    "### Usage Instructions\n",
    "1. **Setup**: \n",
    "    - Install required dependencies:\n",
    "      ```bash\n",
    "      pip install arize-phoenix-otel\n",
    "      ```\n",
    "    - Run the Docker container for Arize Phoenix:\n",
    "      ```bash\n",
    "      docker run -p 6006:6006 -p 4317:4317 --rm arizephoenix/phoenix:latest\n",
    "      ```\n",
    "\n",
    "2. **Execute the Notebook**: Follow the provided steps in the notebook to validate your LightRAG setup against telemetry data.\n",
    "\n",
    "3. **Explore Metrics**:\n",
    "    - Access the Phoenix UI at [http://localhost:6006](http://localhost:6006).\n",
    "    - Analyze detailed traces, latencies, and throughput metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ipywidgets lightrag-hku openai aioboto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define configuration constants\n",
    "DATA_DIR = Path(\"../data\")  # Base data directory\n",
    "INTERIM_DIR = DATA_DIR / \"interim\"  # Interim data directory\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"  # Processed data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define URL and local file path\n",
    "src_file_url = \"https://raw.githubusercontent.com/donbr/kg_rememberall/refs/heads/main/references/winston_churchill_we_shall_fight_speech_june_1940.txt\"\n",
    "file_name = src_file_url.split(\"/\")[-1].replace(\".\", \"_\").lower()\n",
    "\n",
    "WORKING_DIR = INTERIM_DIR / file_name\n",
    "\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and save the file\n",
    "response = requests.get(src_file_url)\n",
    "response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "local_file_path = WORKING_DIR / f\"{file_name}.txt\"\n",
    "local_file_path.write_text(response.text)\n",
    "\n",
    "# Define file paths\n",
    "GRAPHML_FILE = WORKING_DIR / \"graph_chunk_entity_relation.graphml\"\n",
    "PYVIS_HTML_FILE = PROCESSED_DIR / f\"{file_name}.html\"\n",
    "PYVIS_HTML_FILE2 = PROCESSED_DIR / f\"{file_name}2.html\"\n",
    "\n",
    "# Define Neo4j connection parameters\n",
    "os.environ[\"NEO4J_URI\"] = \"neo4j://172.18.176.1:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arize Phoenix\n",
    "\n",
    "- UI endpoint:  http://localhost:6006\n",
    "- NOTE:  the Docker container will be removed when you shut down the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['docker', 'run', '-p', '6006:6006', '-p', '4...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for more information refer to https://docs.arize.com/phoenix/tracing/integrations-tracing/autogen-support#docker\n",
    "# !docker run -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Run the Docker container without interactive mode\n",
    "subprocess.Popen([\n",
    "    \"docker\", \"run\", \"-p\", \"6006:6006\", \"-p\", \"4317:4317\",\n",
    "    \"--rm\", \"arizephoenix/phoenix:latest\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arize Phoenix:  setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ‚Äç‚ôÄÔ∏è‚Äç‚û°Ô∏è Running migrations on the database.\n",
      "---------------------------\n",
      "2025-01-20 04:12:32,405 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-01-20 04:12:32,405 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"alembic_version\")\n",
      "2025-01-20 04:12:32,405 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,406 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"alembic_version\")\n",
      "2025-01-20 04:12:32,406 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,406 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"alembic_version\")\n",
      "2025-01-20 04:12:32,406 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,406 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"alembic_version\")\n",
      "2025-01-20 04:12:32,406 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,407 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE alembic_version (\n",
      "\tversion_num VARCHAR(32) NOT NULL, \n",
      "\tCONSTRAINT alembic_version_pkc PRIMARY KEY (version_num)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,407 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,416 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE projects (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tgradient_start_color VARCHAR DEFAULT '#5bdbff' NOT NULL, \n",
      "\tgradient_end_color VARCHAR DEFAULT '#1c76fc' NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_projects PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_projects_name UNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,416 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-20 04:12:32,420 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE traces (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tproject_rowid INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_traces PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_traces_project_rowid_projects FOREIGN KEY(project_rowid) REFERENCES projects (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_traces_trace_id UNIQUE (trace_id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,420 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:12:32,423 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_rowid ON traces (project_rowid)\n",
      "2025-01-20 04:12:32,423 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-20 04:12:32,426 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_start_time ON traces (start_time)\n",
      "2025-01-20 04:12:32,426 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-20 04:12:32,431 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE spans (\n",
      "\tid INTEGER NOT NULL, \n",
      "\ttrace_rowid INTEGER NOT NULL, \n",
      "\tspan_id VARCHAR NOT NULL, \n",
      "\tparent_id VARCHAR, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tspan_kind VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tattributes JSONB NOT NULL, \n",
      "\tevents JSONB NOT NULL, \n",
      "\tstatus_code VARCHAR DEFAULT 'UNSET' NOT NULL CONSTRAINT \"ck_spans_`valid_status`\" CHECK (status_code IN ('OK', 'ERROR', 'UNSET')), \n",
      "\tstatus_message VARCHAR NOT NULL, \n",
      "\tcumulative_error_count INTEGER NOT NULL, \n",
      "\tcumulative_llm_token_count_prompt INTEGER NOT NULL, \n",
      "\tcumulative_llm_token_count_completion INTEGER NOT NULL, \n",
      "\tCONSTRAINT pk_spans PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_spans_trace_rowid_traces FOREIGN KEY(trace_rowid) REFERENCES traces (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_spans_span_id UNIQUE (span_id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,431 INFO sqlalchemy.engine.Engine [no key 0.00015s] ()\n",
      "2025-01-20 04:12:32,434 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_parent_id ON spans (parent_id)\n",
      "2025-01-20 04:12:32,434 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:12:32,437 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_start_time ON spans (start_time)\n",
      "2025-01-20 04:12:32,437 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-20 04:12:32,440 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_trace_rowid ON spans (trace_rowid)\n",
      "2025-01-20 04:12:32,440 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,443 INFO sqlalchemy.engine.Engine CREATE INDEX ix_latency ON spans ((end_time - start_time))\n",
      "2025-01-20 04:12:32,443 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-20 04:12:32,446 INFO sqlalchemy.engine.Engine CREATE INDEX ix_cumulative_llm_token_count_total ON spans ((cumulative_llm_token_count_prompt + cumulative_llm_token_count_completion))\n",
      "2025-01-20 04:12:32,446 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:12:32,450 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE span_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_span_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_span_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_span_annotations_name_span_rowid UNIQUE (name, span_rowid), \n",
      "\tCONSTRAINT fk_span_annotations_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,451 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-20 04:12:32,454 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_span_rowid ON span_annotations (span_rowid)\n",
      "2025-01-20 04:12:32,454 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:12:32,457 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_label ON span_annotations (label)\n",
      "2025-01-20 04:12:32,457 INFO sqlalchemy.engine.Engine [no key 0.00011s] ()\n",
      "2025-01-20 04:12:32,460 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_score ON span_annotations (score)\n",
      "2025-01-20 04:12:32,460 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:12:32,464 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE trace_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\ttrace_rowid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_trace_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_trace_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_trace_annotations_name_trace_rowid UNIQUE (name, trace_rowid), \n",
      "\tCONSTRAINT fk_trace_annotations_trace_rowid_traces FOREIGN KEY(trace_rowid) REFERENCES traces (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,464 INFO sqlalchemy.engine.Engine [no key 0.00011s] ()\n",
      "2025-01-20 04:12:32,468 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_score ON trace_annotations (score)\n",
      "2025-01-20 04:12:32,468 INFO sqlalchemy.engine.Engine [no key 0.00011s] ()\n",
      "2025-01-20 04:12:32,471 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_trace_rowid ON trace_annotations (trace_rowid)\n",
      "2025-01-20 04:12:32,471 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-20 04:12:32,474 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_label ON trace_annotations (label)\n",
      "2025-01-20 04:12:32,475 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-20 04:12:32,480 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE document_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER NOT NULL, \n",
      "\tdocument_position INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_document_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_document_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_document_annotations_name_span_rowid_document_position UNIQUE (name, span_rowid, document_position), \n",
      "\tCONSTRAINT fk_document_annotations_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,480 INFO sqlalchemy.engine.Engine [no key 0.00011s] ()\n",
      "2025-01-20 04:12:32,483 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_span_rowid ON document_annotations (span_rowid)\n",
      "2025-01-20 04:12:32,483 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-20 04:12:32,488 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_label ON document_annotations (label)\n",
      "2025-01-20 04:12:32,488 INFO sqlalchemy.engine.Engine [no key 0.00017s] ()\n",
      "2025-01-20 04:12:32,492 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_score ON document_annotations (score)\n",
      "2025-01-20 04:12:32,492 INFO sqlalchemy.engine.Engine [no key 0.00022s] ()\n",
      "2025-01-20 04:12:32,497 INFO sqlalchemy.engine.Engine INSERT INTO projects (name, description) VALUES (?, ?)\n",
      "2025-01-20 04:12:32,497 INFO sqlalchemy.engine.Engine [generated in 0.00015s] ('default', 'Default project')\n",
      "2025-01-20 04:12:32,498 INFO sqlalchemy.engine.Engine INSERT INTO alembic_version (version_num) VALUES ('cf03bd6bae1d') RETURNING version_num\n",
      "2025-01-20 04:12:32,498 INFO sqlalchemy.engine.Engine [generated in 0.00010s] ()\n",
      "2025-01-20 04:12:32,498 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE datasets (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_datasets PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_datasets_name UNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,499 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,499 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_versions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_versions PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_dataset_versions_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,499 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,499 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_versions_dataset_id ON dataset_versions (dataset_id)\n",
      "2025-01-20 04:12:32,499 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,502 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_examples (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_examples PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_dataset_examples_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_dataset_examples_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE SET NULL\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,502 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-20 04:12:32,502 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_examples_span_rowid ON dataset_examples (span_rowid)\n",
      "2025-01-20 04:12:32,502 INFO sqlalchemy.engine.Engine [no key 0.00016s] ()\n",
      "2025-01-20 04:12:32,502 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_examples_dataset_id ON dataset_examples (dataset_id)\n",
      "2025-01-20 04:12:32,502 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,503 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_example_revisions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_example_id INTEGER NOT NULL, \n",
      "\tdataset_version_id INTEGER NOT NULL, \n",
      "\tinput JSONB NOT NULL, \n",
      "\toutput JSONB NOT NULL, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\trevision_kind VARCHAR NOT NULL CONSTRAINT \"ck_dataset_example_revisions_`valid_revision_kind`\" CHECK (revision_kind IN ('CREATE', 'PATCH', 'DELETE')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_example_revisions PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_dataset_example_revisions_dataset_example_id_dataset_version_id UNIQUE (dataset_example_id, dataset_version_id), \n",
      "\tCONSTRAINT fk_dataset_example_revisions_dataset_example_id_dataset_examples FOREIGN KEY(dataset_example_id) REFERENCES dataset_examples (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_dataset_example_revisions_dataset_version_id_dataset_versions FOREIGN KEY(dataset_version_id) REFERENCES dataset_versions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,503 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,504 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_example_revisions_dataset_version_id ON dataset_example_revisions (dataset_version_id)\n",
      "2025-01-20 04:12:32,504 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,504 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_example_revisions_dataset_example_id ON dataset_example_revisions (dataset_example_id)\n",
      "2025-01-20 04:12:32,504 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,505 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiments (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tdataset_version_id INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\trepetitions INTEGER NOT NULL, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tproject_name VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_experiments PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_experiments_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_experiments_dataset_version_id_dataset_versions FOREIGN KEY(dataset_version_id) REFERENCES dataset_versions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,505 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,505 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_project_name ON experiments (project_name)\n",
      "2025-01-20 04:12:32,505 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,505 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_dataset_version_id ON experiments (dataset_version_id)\n",
      "2025-01-20 04:12:32,506 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,506 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_dataset_id ON experiments (dataset_id)\n",
      "2025-01-20 04:12:32,506 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,507 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiment_runs (\n",
      "\tid INTEGER NOT NULL, \n",
      "\texperiment_id INTEGER NOT NULL, \n",
      "\tdataset_example_id INTEGER NOT NULL, \n",
      "\trepetition_number INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR, \n",
      "\toutput JSONB NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tprompt_token_count INTEGER, \n",
      "\tcompletion_token_count INTEGER, \n",
      "\terror VARCHAR, \n",
      "\tCONSTRAINT pk_experiment_runs PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_experiment_runs_experiment_id_dataset_example_id_repetition_number UNIQUE (experiment_id, dataset_example_id, repetition_number), \n",
      "\tCONSTRAINT fk_experiment_runs_experiment_id_experiments FOREIGN KEY(experiment_id) REFERENCES experiments (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_experiment_runs_dataset_example_id_dataset_examples FOREIGN KEY(dataset_example_id) REFERENCES dataset_examples (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,507 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,507 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_runs_dataset_example_id ON experiment_runs (dataset_example_id)\n",
      "2025-01-20 04:12:32,507 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,507 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_runs_experiment_id ON experiment_runs (experiment_id)\n",
      "2025-01-20 04:12:32,507 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,508 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiment_run_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\texperiment_run_id INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_experiment_run_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'CODE', 'HUMAN')), \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\ttrace_id VARCHAR, \n",
      "\terror VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_experiment_run_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_experiment_run_annotations_experiment_run_id_name UNIQUE (experiment_run_id, name), \n",
      "\tCONSTRAINT fk_experiment_run_annotations_experiment_run_id_experiment_runs FOREIGN KEY(experiment_run_id) REFERENCES experiment_runs (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,508 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,508 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_run_annotations_experiment_run_id ON experiment_run_annotations (experiment_run_id)\n",
      "2025-01-20 04:12:32,508 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,509 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='10460e46d750' WHERE alembic_version.version_num = 'cf03bd6bae1d'\n",
      "2025-01-20 04:12:32,509 INFO sqlalchemy.engine.Engine [generated in 0.00011s] ()\n",
      "2025-01-20 04:12:32,509 INFO sqlalchemy.engine.Engine ALTER TABLE spans ADD COLUMN llm_token_count_prompt INTEGER\n",
      "2025-01-20 04:12:32,509 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,510 INFO sqlalchemy.engine.Engine ALTER TABLE spans ADD COLUMN llm_token_count_completion INTEGER\n",
      "2025-01-20 04:12:32,510 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,511 INFO sqlalchemy.engine.Engine UPDATE spans SET llm_token_count_prompt=(JSON_EXTRACT(spans.attributes, ?)), llm_token_count_completion=(JSON_EXTRACT(spans.attributes, ?))\n",
      "2025-01-20 04:12:32,511 INFO sqlalchemy.engine.Engine [generated in 0.00014s] ('$.\"llm\".\"token_count\".\"prompt\"', '$.\"llm\".\"token_count\".\"completion\"')\n",
      "2025-01-20 04:12:32,511 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='3be8647b87d8' WHERE alembic_version.version_num = '10460e46d750'\n",
      "2025-01-20 04:12:32,512 INFO sqlalchemy.engine.Engine [generated in 0.00008s] ()\n",
      "2025-01-20 04:12:32,512 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE user_roles (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tCONSTRAINT pk_user_roles PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,512 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,512 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_user_roles_name ON user_roles (name)\n",
      "2025-01-20 04:12:32,512 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,514 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE users (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_role_id INTEGER NOT NULL, \n",
      "\tusername VARCHAR NOT NULL, \n",
      "\temail VARCHAR NOT NULL, \n",
      "\tprofile_picture_url VARCHAR, \n",
      "\tpassword_hash BLOB, \n",
      "\tpassword_salt BLOB, \n",
      "\treset_password BOOLEAN NOT NULL, \n",
      "\toauth2_client_id VARCHAR, \n",
      "\toauth2_user_id VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT \"ck_users_`password_hash_and_salt`\" CHECK ((password_hash IS NULL) = (password_salt IS NULL)), \n",
      "\tCONSTRAINT \"ck_users_`oauth2_client_id_and_user_id`\" CHECK ((oauth2_client_id IS NULL) = (oauth2_user_id IS NULL)), \n",
      "\tCONSTRAINT \"ck_users_`exactly_one_auth_method`\" CHECK ((password_hash IS NULL) != (oauth2_client_id IS NULL)), \n",
      "\tCONSTRAINT uq_users_oauth2_client_id_oauth2_user_id UNIQUE (oauth2_client_id, oauth2_user_id), \n",
      "\tCONSTRAINT fk_users_user_role_id_user_roles FOREIGN KEY(user_role_id) REFERENCES user_roles (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,514 INFO sqlalchemy.engine.Engine [no key 0.00011s] ()\n",
      "2025-01-20 04:12:32,514 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_users_email ON users (email)\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_oauth2_user_id ON users (oauth2_user_id)\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_user_role_id ON users (user_role_id)\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_users_username ON users (username)\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_oauth2_client_id ON users (oauth2_client_id)\n",
      "2025-01-20 04:12:32,515 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,516 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE password_reset_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT fk_password_reset_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,516 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-20 04:12:32,516 INFO sqlalchemy.engine.Engine CREATE INDEX ix_password_reset_tokens_expires_at ON password_reset_tokens (expires_at)\n",
      "2025-01-20 04:12:32,516 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,516 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_password_reset_tokens_user_id ON password_reset_tokens (user_id)\n",
      "2025-01-20 04:12:32,516 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,517 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE refresh_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT fk_refresh_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,517 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-20 04:12:32,518 INFO sqlalchemy.engine.Engine CREATE INDEX ix_refresh_tokens_user_id ON refresh_tokens (user_id)\n",
      "2025-01-20 04:12:32,518 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,518 INFO sqlalchemy.engine.Engine CREATE INDEX ix_refresh_tokens_expires_at ON refresh_tokens (expires_at)\n",
      "2025-01-20 04:12:32,518 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE access_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\trefresh_token_id INTEGER, \n",
      "\tCONSTRAINT fk_access_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_access_tokens_refresh_token_id_refresh_tokens FOREIGN KEY(refresh_token_id) REFERENCES refresh_tokens (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine CREATE INDEX ix_access_tokens_expires_at ON access_tokens (expires_at)\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine CREATE INDEX ix_access_tokens_user_id ON access_tokens (user_id)\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_access_tokens_refresh_token_id ON access_tokens (refresh_token_id)\n",
      "2025-01-20 04:12:32,519 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,520 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE api_keys (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP, \n",
      "\tCONSTRAINT fk_api_keys_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,520 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,520 INFO sqlalchemy.engine.Engine CREATE INDEX ix_api_keys_user_id ON api_keys (user_id)\n",
      "2025-01-20 04:12:32,520 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,520 INFO sqlalchemy.engine.Engine CREATE INDEX ix_api_keys_expires_at ON api_keys (expires_at)\n",
      "2025-01-20 04:12:32,520 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,521 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='cd164e83824f' WHERE alembic_version.version_num = '3be8647b87d8'\n",
      "2025-01-20 04:12:32,521 INFO sqlalchemy.engine.Engine [generated in 0.00013s] ()\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE project_sessions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tsession_id VARCHAR NOT NULL, \n",
      "\tproject_id INTEGER NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_project_sessions PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_project_sessions_session_id UNIQUE (session_id), \n",
      "\tCONSTRAINT fk_project_sessions_project_id_projects FOREIGN KEY(project_id) REFERENCES projects (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_project_id ON project_sessions (project_id)\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_start_time ON project_sessions (start_time)\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_end_time ON project_sessions (end_time)\n",
      "2025-01-20 04:12:32,522 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"traces\")\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"traces\")\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:12:32,523 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"traces\")\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_start_time\")\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_project_rowid\")\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"traces\")\n",
      "2025-01-20 04:12:32,525 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_start_time\")\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_project_rowid\")\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"sqlite_autoindex_traces_1\")\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:12:32,526 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"projects\")\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"projects\")\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine PRAGMA temp.foreign_key_list(\"projects\")\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:12:32,527 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"projects\")\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"projects\")\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"projects\")\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"sqlite_autoindex_projects_1\")\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:12:32,528 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-20 04:12:32,530 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE _alembic_tmp_traces (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tproject_rowid INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tproject_session_rowid INTEGER, \n",
      "\tCONSTRAINT pk_traces PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_traces_trace_id UNIQUE (trace_id), \n",
      "\tCONSTRAINT fk_traces_project_rowid_projects FOREIGN KEY(project_rowid) REFERENCES projects (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_traces_project_session_rowid_project_sessions FOREIGN KEY(project_session_rowid) REFERENCES project_sessions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:12:32,530 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:12:32,531 INFO sqlalchemy.engine.Engine INSERT INTO _alembic_tmp_traces (id, project_rowid, trace_id, start_time, end_time) SELECT traces.id, traces.project_rowid, traces.trace_id, traces.start_time, traces.end_time \n",
      "FROM traces\n",
      "2025-01-20 04:12:32,531 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-20 04:12:32,531 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE traces\n",
      "2025-01-20 04:12:32,531 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,531 INFO sqlalchemy.engine.Engine ALTER TABLE _alembic_tmp_traces RENAME TO traces\n",
      "2025-01-20 04:12:32,531 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,532 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_start_time ON traces (start_time)\n",
      "2025-01-20 04:12:32,532 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,532 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_rowid ON traces (project_rowid)\n",
      "2025-01-20 04:12:32,532 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:12:32,532 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_session_rowid ON traces (project_session_rowid)\n",
      "2025-01-20 04:12:32,532 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:12:32,533 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='4ded9e43755f' WHERE alembic_version.version_num = 'cd164e83824f'\n",
      "2025-01-20 04:12:32,533 INFO sqlalchemy.engine.Engine [generated in 0.00008s] ()\n",
      "2025-01-20 04:12:32,533 INFO sqlalchemy.engine.Engine COMMIT\n",
      "---------------------------\n",
      "‚úÖ Migrations completed in 0.136 seconds.\n",
      "\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ïî‚ïù\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïó\n",
      "‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù v7.7.1\n",
      "\n",
      "|\n",
      "|  üåé Join our Community üåé\n",
      "|  https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\n",
      "|\n",
      "|  ‚≠êÔ∏è Leave us a Star ‚≠êÔ∏è\n",
      "|  https://github.com/Arize-ai/phoenix\n",
      "|\n",
      "|  üìö Documentation üìö\n",
      "|  https://docs.arize.com/phoenix\n",
      "|\n",
      "|  üöÄ Phoenix Server üöÄ\n",
      "|  Phoenix UI: http://0.0.0.0:6006\n",
      "|  Authentication: False\n",
      "|  Websockets: True\n",
      "|  Log traces:\n",
      "|    - gRPC: http://0.0.0.0:4317\n",
      "|    - HTTP: http://0.0.0.0:6006/v1/traces\n",
      "|  Storage: sqlite:////root/.phoenix/phoenix.db\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:6006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q arize-phoenix-otel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: lightrag-openai\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'authorization': '****', 'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "# defaults to endpoint=\"http://localhost:4317\"\n",
    "tracer_provider = register(\n",
    "  project_name=\"lightrag-openai\", # Default is 'default'\n",
    "  endpoint=\"http://localhost:4317\",  # Sends traces using gRPC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## install python telemetry and openai library requirements\n",
    "%pip install -q openinference-instrumentation-openai openai 'httpx<0.28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Use Case\n",
    "\n",
    "Monitor LightRAG‚Äôs real-time LLM and embedding model usage\n",
    "- performance and response latencies\n",
    "- model behavior and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the Graph\n",
    "\n",
    "- Initialize LightRAG and OpenAI connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install Ollama as LightRAG requires it\n",
    "%pip install -q ollama tiktoken nano_vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: ../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt\n",
      "DEBUG:lightrag:LightRAG init with param:\n",
      "  working_dir = ../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt,\n",
      "  embedding_cache_config = {'enabled': False, 'similarity_threshold': 0.95, 'use_llm_check': False},\n",
      "  kv_storage = JsonKVStorage,\n",
      "  vector_storage = NanoVectorDBStorage,\n",
      "  graph_storage = Neo4JStorage,\n",
      "  log_level = DEBUG,\n",
      "  chunk_token_size = 1200,\n",
      "  chunk_overlap_token_size = 100,\n",
      "  tiktoken_model_name = gpt-4o-mini,\n",
      "  entity_extract_max_gleaning = 1,\n",
      "  entity_summary_to_max_tokens = 500,\n",
      "  node_embedding_algorithm = node2vec,\n",
      "  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},\n",
      "  embedding_func = {'embedding_dim': 1536, 'max_token_size': 8192, 'func': <function openai_embedding at 0x7f689d6751c0>, 'concurrent_limit': 16},\n",
      "  embedding_batch_num = 32,\n",
      "  embedding_func_max_async = 16,\n",
      "  llm_model_func = <function gpt_4o_mini_complete at 0x7f689d6740e0>,\n",
      "  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,\n",
      "  llm_model_max_token_size = 32768,\n",
      "  llm_model_max_async = 16,\n",
      "  llm_model_kwargs = {},\n",
      "  vector_db_storage_cls_kwargs = {},\n",
      "  enable_llm_cache = True,\n",
      "  enable_llm_cache_for_entity_extract = True,\n",
      "  addon_params = {},\n",
      "  convert_response_to_json_func = <function convert_response_to_json at 0x7f6877f85120>,\n",
      "  doc_status_storage = JsonDocStatusStorage,\n",
      "  chunking_func = <function chunking_by_token_size at 0x7f6877f87ec0>,\n",
      "  chunking_func_kwargs = {}\n",
      "\n",
      "INFO:lightrag:Load KV llm_response_cache with 2 data\n",
      "INFO:lightrag:Load KV full_docs with 1 data\n",
      "INFO:lightrag:Load KV text_chunks with 5 data\n",
      "INFO:lightrag:Connected to None at neo4j://172.18.176.1:7687\n",
      "INFO:nano-vectordb:Load (80, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_entities.json'} 80 data\n",
      "INFO:nano-vectordb:Load (49, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_relationships.json'} 49 data\n",
      "INFO:nano-vectordb:Load (5, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_chunks.json'} 5 data\n",
      "INFO:lightrag:Loaded document status storage with 1 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm import gpt_4o_mini_complete\n",
    "import nano_vectordb\n",
    "\n",
    "#########\n",
    "# Uncomment the below two lines if running in a jupyter notebook to handle the async nature of rag.insert()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "#########\n",
    "\n",
    "# When you launch the project be sure to override the default KG: NetworkX\n",
    "# by specifying kg=\"Neo4JStorage\".\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model\n",
    "    graph_storage=\"Neo4JStorage\", #<-----------override KG default\n",
    "    log_level=\"DEBUG\"  #<-----------override log_level default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:All documents have been processed or are duplicates\n"
     ]
    }
   ],
   "source": [
    "with open(local_file_path) as f:\n",
    "    rag.insert(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## APPROACH 4\n",
      "\n",
      "### The Role of King Leopold During the Dunkirk Evacuation\n",
      "\n",
      "King Leopold of Belgium played a significant and complex role during the evacuation of Dunkirk in World War II. His actions had far-reaching consequences on the situation for Allied forces, particularly the British and French armies.\n",
      "\n",
      "Initially, Belgium sought to maintain its neutrality when the conflict erupted, but the German invasion challenged this stance. As the German forces advanced, King Leopold called upon the British and French militaries for assistance, emphasizing the need for support to defend Belgium against the encroaching enemy. This appeal was crucial in the early stages of the invasion as it highlighted Belgium's strategic importance and the necessity for a coordinated defense among the Allies.\n",
      "\n",
      "However, the situation drastically changed when King Leopold made a unilateral decision to surrender the Belgian Army to the Germans. This action occurred unexpectedly and without prior consultation with his ministers. The surrender exposed the flank of the British and French forces, drastically altering the strategic dynamics on the ground. In essence, the Belgian King's capitulation compelled the British Expeditionary Force to cover a significantly longer and more vulnerable retreat path toward the coast, thereby complicating evacuation efforts.\n",
      "\n",
      "### Consequences for the Allied Forces\n",
      "\n",
      "The hasty surrender of the Belgian Army not only weakened the defensive line against the German advance but also hampered the coordinated efforts of the Allies at Dunkirk. The British and French armies found themselves isolated and under severe pressure from German forces, which had been bolstered by the lack of support from the Belgian troops.\n",
      "\n",
      "King Leopold's decision is often viewed critically, as it significantly affected the Allied strategy and ultimately contributed to the chaos that ensued during the Dunkirk evacuation. This event underscored the fragility of alliances and the impact of leadership decisions in the face of rapidly changing military conditions. The collective Allied response and the efforts of the British and French troops on the beaches of Dunkirk became a testament to their bravery, but King Leopold's actions will forever remain a pivotal part of the narrative surrounding the Belgian Army and the broader campaign during World War II.\n"
     ]
    }
   ],
   "source": [
    "# Perform hybrid search\n",
    "print(\"\\n## APPROACH 4\\n\")\n",
    "print(rag.query(\"What role did King Leopold play during the evacuation of Dunkirk?\", param=QueryParam(mode=\"hybrid\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Graph\n",
    "\n",
    "- graph visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Telemetry data\n",
    "\n",
    "- Access the Arize Phoenix UI at [http://localhost:6006](http://localhost:6006)\n",
    "- both LLM inference and embedding telemetry information is captured"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
