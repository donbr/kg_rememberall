{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install -q networkx pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set BROWSER env variable\n",
    "import os\n",
    "os.environ[\"BROWSER\"] = os.getenv(\"BROWSER\", \"chromium-browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-20 14:23:14.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkg_rememberall.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/donbr/kgmgmt/kg_rememberall\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "../data/processed/glirel_paper_networkx_vizualization_pyvis.html\n",
      "Graph successfully created and saved. \n",
      "GraphML: ../data/processed/glirel_paper_networkx_vizualization.graphml, \n",
      "JSON: ../data/processed/glirel_paper_networkx_vizualization.json, \n",
      "PyVis: ../data/processed/glirel_paper_networkx_vizualization_pyvis.html\n"
     ]
    }
   ],
   "source": [
    "# Import the utility library\n",
    "from kg_rememberall.utils import networkx_utils as utils\n",
    "\n",
    "# Define the sections and subsections\n",
    "sections = {\n",
    "    \"Abstract\": {\"summary\": \"Overview of GLiREL's novel approach for zero-shot relation classification.\", \"type\": \"section\"},\n",
    "    \"1 Introduction\": {\"summary\": \"Motivation and importance of efficient zero-shot relation extraction.\", \"type\": \"section\"},\n",
    "    \"2 Background\": {\"summary\": \"Discussion of prior work, including NER and zero-shot techniques.\", \"type\": \"section\"},\n",
    "    \"3 Method\": {\"summary\": \"Details of GLiREL's architecture and training methodology.\", \"type\": \"section\"},\n",
    "    \"4 Experiments\": {\"summary\": \"Empirical evaluation using benchmark datasets and results.\", \"type\": \"section\"},\n",
    "    \"5 Analysis\": {\"summary\": \"Performance analysis, including inference speed and ablation studies.\", \"type\": \"section\"},\n",
    "    \"6 Conclusion\": {\"summary\": \"Summary of findings and GLiREL's contributions.\", \"type\": \"section\"},\n",
    "    \"7 Limitations\": {\"summary\": \"Discussion of limitations and future directions.\", \"type\": \"section\"},\n",
    "    \"References\": {\"summary\": \"List of cited works and related research.\", \"type\": \"section\"},\n",
    "    \"Appendix\": {\"summary\": \"Supplementary material, including extended results and technical details.\", \"type\": \"section\"}\n",
    "}\n",
    "\n",
    "subsections = {\n",
    "    \"2 Background\": [\n",
    "        (\"Joint vs Independent NER and Relation Classification\", {\"summary\": \"Compares joint and independent approaches to NER and relation classification.\", \"type\": \"subsection\"}),\n",
    "        (\"Zero-Shot Relation Extraction\", {\"summary\": \"Reviews existing zero-shot relation extraction models.\", \"type\": \"subsection\"}),\n",
    "        (\"LLMs for Relation Classification\", {\"summary\": \"Explores the use of LLMs for relation classification.\", \"type\": \"subsection\"}),\n",
    "        (\"Zero-Shot Learning and Synthetic Training Data Generation\", {\"summary\": \"Highlights synthetic data generation for training zero-shot models.\", \"type\": \"subsection\"})\n",
    "    ],\n",
    "    \"3 Method\": [\n",
    "        (\"Input\", {\"summary\": \"Details the input structure, including relation labels, text tokens, and entity indices.\", \"type\": \"subsection\"}),\n",
    "        (\"Token Representation\", {\"summary\": \"Explains how tokens are encoded and represented in the model.\", \"type\": \"subsection\"}),\n",
    "        (\"Label and Entity Pair Representation\", {\"summary\": \"Describes how relation labels and entity pairs are encoded.\", \"type\": \"subsection\"}),\n",
    "        (\"Refinement Layer\", {\"summary\": \"Explains the refinement process using attention mechanisms.\", \"type\": \"subsection\"}),\n",
    "        (\"Scoring Layer\", {\"summary\": \"Details the scoring mechanism for relationships between entity pairs and relation types.\", \"type\": \"subsection\"}),\n",
    "        (\"Training Dataset Generation\", {\"summary\": \"Outlines the protocol for generating synthetic training data.\", \"type\": \"subsection\"}),\n",
    "        (\"Extending to Coreference Resolution and Document-Level Relation Classification\", {\"summary\": \"Discusses extending GLiREL for document-level relation classification.\", \"type\": \"subsection\"})\n",
    "    ],\n",
    "    \"4 Experiments\": [\n",
    "        (\"Relation Classification Datasets\", {\"summary\": \"Describes the Wiki-ZSL and FewRel datasets used for evaluation.\", \"type\": \"subsection\"}),\n",
    "        (\"Zero-Shot Relation Classification Settings\", {\"summary\": \"Explains the experimental setup and evaluation metrics.\", \"type\": \"subsection\"}),\n",
    "        (\"Results\", {\"summary\": \"Reports GLiREL's performance with state-of-the-art results.\", \"type\": \"subsection\"})\n",
    "    ],\n",
    "    \"5 Analysis\": [\n",
    "        (\"Inference Speed\", {\"summary\": \"Compares inference speed of GLiREL with other models.\", \"type\": \"subsection\"}),\n",
    "        (\"Ablation Study\", {\"summary\": \"Examines the impact of various components on model performance.\", \"type\": \"subsection\"})\n",
    "    ],\n",
    "    \"Appendix\": [\n",
    "        (\"Extended Related Work\", {\"summary\": \"Further discusses existing approaches to relation extraction.\", \"type\": \"subsection\"}),\n",
    "        (\"Tokenization Details\", {\"summary\": \"Explains the tokenization process.\", \"type\": \"subsection\"}),\n",
    "        (\"GPT-4o Baseline Prompt\", {\"summary\": \"Provides the prompt used for baseline experiments.\", \"type\": \"subsection\"}),\n",
    "        (\"Synthetic Data Generation Details\", {\"summary\": \"Details the process of generating synthetic training data.\", \"type\": \"subsection\"}),\n",
    "        (\"Training Setup Details\", {\"summary\": \"Describes training hyperparameters and configuration.\", \"type\": \"subsection\"}),\n",
    "        (\"Full Zero-Shot Relation Classification Results\", {\"summary\": \"Presents extended results for relation classification.\", \"type\": \"subsection\"}),\n",
    "        (\"Coreference Resolution and Document-level Relation Classification\", {\"summary\": \"Explores document-level relation classification.\", \"type\": \"subsection\"})\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define the color scheme\n",
    "color_scheme = {\n",
    "    \"section\": \"lightblue\",\n",
    "    \"subsection\": \"lightgreen\"\n",
    "}\n",
    "\n",
    "# Export and visualize the graph\n",
    "output_prefix = \"glirel_paper_networkx_vizualization\"\n",
    "graphml_path = f\"../data/processed/{output_prefix}.graphml\"\n",
    "json_path = f\"../data/processed/{output_prefix}.json\"\n",
    "pyvis_path = f\"../data/processed/{output_prefix}_pyvis.html\"\n",
    "\n",
    "# Create the NetworkX graph\n",
    "graph = utils.create_graph_using_dict(sections, subsections, color_scheme)\n",
    "\n",
    "# Save as GraphML and JSON\n",
    "utils.export_to_graphml(graph, filename=graphml_path)\n",
    "utils.export_to_json(graph, filename=json_path)\n",
    "\n",
    "# Visualize with PyVis\n",
    "utils.visualize_with_pyvis(graph, output_file=pyvis_path)\n",
    "\n",
    "print(f\"Graph successfully created and saved. \\nGraphML: {graphml_path}, \\nJSON: {json_path}, \\nPyVis: {pyvis_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
