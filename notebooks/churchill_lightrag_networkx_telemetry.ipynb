{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winston Churchill - breaking down a memorable speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_QUERY=\"What role did King Leopold play during the evacuation of Dunkirk?\"\n",
    "\n",
    "SRC_FILE_URL = \"https://raw.githubusercontent.com/donbr/kg_rememberall/refs/heads/main/references/winston_churchill_we_shall_fight_speech_june_1940.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ipywidgets lightrag-hku openai aioboto3 tiktoken nano_vectordb\n",
    "%pip install -q arize-phoenix-otel openinference-instrumentation-openai openai 'httpx<0.28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define configuration constants\n",
    "DATA_DIR = Path(\"../data\")  # Base data directory\n",
    "INTERIM_DIR = DATA_DIR / \"interim\"  # Interim data directory\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"  # Processed data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "# Define URL and local file path\n",
    "SRC_FILE_URL = \"https://raw.githubusercontent.com/donbr/kg_rememberall/refs/heads/main/references/winston_churchill_we_shall_fight_speech_june_1940.txt\"\n",
    "file_name = SRC_FILE_URL.split(\"/\")[-1].replace(\".\", \"_\").lower()\n",
    "\n",
    "WORKING_DIR = INTERIM_DIR / file_name\n",
    "\n",
    "# Replace operation: ensure WORKING_DIR is fresh\n",
    "if os.path.exists(WORKING_DIR):\n",
    "    shutil.rmtree(WORKING_DIR)  # Remove the existing directory and its contents\n",
    "os.mkdir(WORKING_DIR)           # Create a new, empty directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and save the file\n",
    "response = requests.get(SRC_FILE_URL)\n",
    "response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "local_file_path = WORKING_DIR / f\"{file_name}.txt\"\n",
    "local_file_path.write_text(response.text)\n",
    "\n",
    "# Define file paths\n",
    "GRAPHML_FILE = WORKING_DIR / f\"graph_chunk_entity_relation.graphml\"\n",
    "PYVIS_HTML_FILE = PROCESSED_DIR / f\"{file_name}.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arize Phoenix - telemetry\n",
    "\n",
    "- UI endpoint:  http://localhost:6006\n",
    "- NOTE:  the Docker container will be removed when you shut down the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['docker', 'run', '-p', '6006:6006', '-p', '4...>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for more information refer to https://docs.arize.com/phoenix/tracing/integrations-tracing/autogen-support#docker\n",
    "# !docker run -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Run the Docker container without interactive mode\n",
    "subprocess.Popen([\n",
    "    \"docker\", \"run\", \"-p\", \"6006:6006\", \"-p\", \"4317:4317\",\n",
    "    \"--rm\", \"arizephoenix/phoenix:latest\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: lightrag-openai\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'authorization': '****', 'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "# defaults to endpoint=\"http://localhost:4317\"\n",
    "tracer_provider = register(\n",
    "  project_name=\"lightrag-openai\", # Default is 'default'\n",
    "  endpoint=\"http://localhost:4317\",  # Sends traces using gRPC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Graph\n",
    "\n",
    "- Initialize LightRAG and OpenAI connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ‚Äç‚ôÄÔ∏è‚Äç‚û°Ô∏è Running migrations on the database.\n",
      "---------------------------\n",
      "2025-01-21 00:01:44,253 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-01-21 00:01:44,253 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"alembic_version\")\n",
      "2025-01-21 00:01:44,253 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,254 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"alembic_version\")\n",
      "2025-01-21 00:01:44,254 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,254 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"alembic_version\")\n",
      "2025-01-21 00:01:44,254 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,254 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"alembic_version\")\n",
      "2025-01-21 00:01:44,254 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,255 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE alembic_version (\n",
      "\tversion_num VARCHAR(32) NOT NULL, \n",
      "\tCONSTRAINT alembic_version_pkc PRIMARY KEY (version_num)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,255 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,265 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE projects (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tgradient_start_color VARCHAR DEFAULT '#5bdbff' NOT NULL, \n",
      "\tgradient_end_color VARCHAR DEFAULT '#1c76fc' NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_projects PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_projects_name UNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,265 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,269 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE traces (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tproject_rowid INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_traces PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_traces_project_rowid_projects FOREIGN KEY(project_rowid) REFERENCES projects (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_traces_trace_id UNIQUE (trace_id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,269 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,272 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_start_time ON traces (start_time)\n",
      "2025-01-21 00:01:44,272 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-21 00:01:44,276 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_rowid ON traces (project_rowid)\n",
      "2025-01-21 00:01:44,276 INFO sqlalchemy.engine.Engine [no key 0.00014s] ()\n",
      "2025-01-21 00:01:44,281 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE spans (\n",
      "\tid INTEGER NOT NULL, \n",
      "\ttrace_rowid INTEGER NOT NULL, \n",
      "\tspan_id VARCHAR NOT NULL, \n",
      "\tparent_id VARCHAR, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tspan_kind VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tattributes JSONB NOT NULL, \n",
      "\tevents JSONB NOT NULL, \n",
      "\tstatus_code VARCHAR DEFAULT 'UNSET' NOT NULL CONSTRAINT \"ck_spans_`valid_status`\" CHECK (status_code IN ('OK', 'ERROR', 'UNSET')), \n",
      "\tstatus_message VARCHAR NOT NULL, \n",
      "\tcumulative_error_count INTEGER NOT NULL, \n",
      "\tcumulative_llm_token_count_prompt INTEGER NOT NULL, \n",
      "\tcumulative_llm_token_count_completion INTEGER NOT NULL, \n",
      "\tCONSTRAINT pk_spans PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_spans_trace_rowid_traces FOREIGN KEY(trace_rowid) REFERENCES traces (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_spans_span_id UNIQUE (span_id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,281 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,284 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_trace_rowid ON spans (trace_rowid)\n",
      "2025-01-21 00:01:44,284 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-21 00:01:44,288 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_start_time ON spans (start_time)\n",
      "2025-01-21 00:01:44,288 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-21 00:01:44,291 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_parent_id ON spans (parent_id)\n",
      "2025-01-21 00:01:44,291 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-21 00:01:44,294 INFO sqlalchemy.engine.Engine CREATE INDEX ix_latency ON spans ((end_time - start_time))\n",
      "2025-01-21 00:01:44,295 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,298 INFO sqlalchemy.engine.Engine CREATE INDEX ix_cumulative_llm_token_count_total ON spans ((cumulative_llm_token_count_prompt + cumulative_llm_token_count_completion))\n",
      "2025-01-21 00:01:44,298 INFO sqlalchemy.engine.Engine [no key 0.00011s] ()\n",
      "2025-01-21 00:01:44,302 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE span_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_span_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_span_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_span_annotations_name_span_rowid UNIQUE (name, span_rowid), \n",
      "\tCONSTRAINT fk_span_annotations_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,302 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,306 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_span_rowid ON span_annotations (span_rowid)\n",
      "2025-01-21 00:01:44,307 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,310 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_label ON span_annotations (label)\n",
      "2025-01-21 00:01:44,310 INFO sqlalchemy.engine.Engine [no key 0.00017s] ()\n",
      "2025-01-21 00:01:44,314 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_score ON span_annotations (score)\n",
      "2025-01-21 00:01:44,314 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,320 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE trace_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\ttrace_rowid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_trace_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_trace_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_trace_annotations_name_trace_rowid UNIQUE (name, trace_rowid), \n",
      "\tCONSTRAINT fk_trace_annotations_trace_rowid_traces FOREIGN KEY(trace_rowid) REFERENCES traces (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,320 INFO sqlalchemy.engine.Engine [no key 0.00015s] ()\n",
      "2025-01-21 00:01:44,323 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_score ON trace_annotations (score)\n",
      "2025-01-21 00:01:44,323 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-21 00:01:44,327 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_trace_rowid ON trace_annotations (trace_rowid)\n",
      "2025-01-21 00:01:44,327 INFO sqlalchemy.engine.Engine [no key 0.00014s] ()\n",
      "2025-01-21 00:01:44,331 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_label ON trace_annotations (label)\n",
      "2025-01-21 00:01:44,331 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,335 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE document_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER NOT NULL, \n",
      "\tdocument_position INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_document_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_document_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_document_annotations_name_span_rowid_document_position UNIQUE (name, span_rowid, document_position), \n",
      "\tCONSTRAINT fk_document_annotations_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,335 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,338 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_score ON document_annotations (score)\n",
      "2025-01-21 00:01:44,339 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-21 00:01:44,342 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_label ON document_annotations (label)\n",
      "2025-01-21 00:01:44,342 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-21 00:01:44,346 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_span_rowid ON document_annotations (span_rowid)\n",
      "2025-01-21 00:01:44,346 INFO sqlalchemy.engine.Engine [no key 0.00012s] ()\n",
      "2025-01-21 00:01:44,350 INFO sqlalchemy.engine.Engine INSERT INTO projects (name, description) VALUES (?, ?)\n",
      "2025-01-21 00:01:44,350 INFO sqlalchemy.engine.Engine [generated in 0.00017s] ('default', 'Default project')\n",
      "2025-01-21 00:01:44,350 INFO sqlalchemy.engine.Engine INSERT INTO alembic_version (version_num) VALUES ('cf03bd6bae1d') RETURNING version_num\n",
      "2025-01-21 00:01:44,351 INFO sqlalchemy.engine.Engine [generated in 0.00011s] ()\n",
      "2025-01-21 00:01:44,351 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE datasets (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_datasets PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_datasets_name UNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,351 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-21 00:01:44,352 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_versions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_versions PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_dataset_versions_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,352 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-21 00:01:44,352 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_versions_dataset_id ON dataset_versions (dataset_id)\n",
      "2025-01-21 00:01:44,353 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,355 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_examples (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_examples PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_dataset_examples_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_dataset_examples_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE SET NULL\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,355 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-21 00:01:44,355 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_examples_span_rowid ON dataset_examples (span_rowid)\n",
      "2025-01-21 00:01:44,355 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,355 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_examples_dataset_id ON dataset_examples (dataset_id)\n",
      "2025-01-21 00:01:44,355 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,356 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_example_revisions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_example_id INTEGER NOT NULL, \n",
      "\tdataset_version_id INTEGER NOT NULL, \n",
      "\tinput JSONB NOT NULL, \n",
      "\toutput JSONB NOT NULL, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\trevision_kind VARCHAR NOT NULL CONSTRAINT \"ck_dataset_example_revisions_`valid_revision_kind`\" CHECK (revision_kind IN ('CREATE', 'PATCH', 'DELETE')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_example_revisions PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_dataset_example_revisions_dataset_example_id_dataset_version_id UNIQUE (dataset_example_id, dataset_version_id), \n",
      "\tCONSTRAINT fk_dataset_example_revisions_dataset_example_id_dataset_examples FOREIGN KEY(dataset_example_id) REFERENCES dataset_examples (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_dataset_example_revisions_dataset_version_id_dataset_versions FOREIGN KEY(dataset_version_id) REFERENCES dataset_versions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,356 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,356 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_example_revisions_dataset_version_id ON dataset_example_revisions (dataset_version_id)\n",
      "2025-01-21 00:01:44,356 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,356 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_example_revisions_dataset_example_id ON dataset_example_revisions (dataset_example_id)\n",
      "2025-01-21 00:01:44,356 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,357 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiments (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tdataset_version_id INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\trepetitions INTEGER NOT NULL, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tproject_name VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_experiments PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_experiments_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_experiments_dataset_version_id_dataset_versions FOREIGN KEY(dataset_version_id) REFERENCES dataset_versions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,358 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,358 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_dataset_id ON experiments (dataset_id)\n",
      "2025-01-21 00:01:44,358 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-21 00:01:44,358 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_project_name ON experiments (project_name)\n",
      "2025-01-21 00:01:44,358 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,358 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_dataset_version_id ON experiments (dataset_version_id)\n",
      "2025-01-21 00:01:44,358 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,359 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiment_runs (\n",
      "\tid INTEGER NOT NULL, \n",
      "\texperiment_id INTEGER NOT NULL, \n",
      "\tdataset_example_id INTEGER NOT NULL, \n",
      "\trepetition_number INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR, \n",
      "\toutput JSONB NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tprompt_token_count INTEGER, \n",
      "\tcompletion_token_count INTEGER, \n",
      "\terror VARCHAR, \n",
      "\tCONSTRAINT pk_experiment_runs PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_experiment_runs_experiment_id_dataset_example_id_repetition_number UNIQUE (experiment_id, dataset_example_id, repetition_number), \n",
      "\tCONSTRAINT fk_experiment_runs_experiment_id_experiments FOREIGN KEY(experiment_id) REFERENCES experiments (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_experiment_runs_dataset_example_id_dataset_examples FOREIGN KEY(dataset_example_id) REFERENCES dataset_examples (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,359 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-21 00:01:44,359 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_runs_experiment_id ON experiment_runs (experiment_id)\n",
      "2025-01-21 00:01:44,359 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,359 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_runs_dataset_example_id ON experiment_runs (dataset_example_id)\n",
      "2025-01-21 00:01:44,359 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,360 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiment_run_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\texperiment_run_id INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_experiment_run_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'CODE', 'HUMAN')), \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\ttrace_id VARCHAR, \n",
      "\terror VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_experiment_run_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_experiment_run_annotations_experiment_run_id_name UNIQUE (experiment_run_id, name), \n",
      "\tCONSTRAINT fk_experiment_run_annotations_experiment_run_id_experiment_runs FOREIGN KEY(experiment_run_id) REFERENCES experiment_runs (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,360 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-21 00:01:44,361 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_run_annotations_experiment_run_id ON experiment_run_annotations (experiment_run_id)\n",
      "2025-01-21 00:01:44,361 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-21 00:01:44,362 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='10460e46d750' WHERE alembic_version.version_num = 'cf03bd6bae1d'\n",
      "2025-01-21 00:01:44,362 INFO sqlalchemy.engine.Engine [generated in 0.00011s] ()\n",
      "2025-01-21 00:01:44,362 INFO sqlalchemy.engine.Engine ALTER TABLE spans ADD COLUMN llm_token_count_prompt INTEGER\n",
      "2025-01-21 00:01:44,362 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,362 INFO sqlalchemy.engine.Engine ALTER TABLE spans ADD COLUMN llm_token_count_completion INTEGER\n",
      "2025-01-21 00:01:44,362 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,364 INFO sqlalchemy.engine.Engine UPDATE spans SET llm_token_count_prompt=(JSON_EXTRACT(spans.attributes, ?)), llm_token_count_completion=(JSON_EXTRACT(spans.attributes, ?))\n",
      "2025-01-21 00:01:44,364 INFO sqlalchemy.engine.Engine [generated in 0.00014s] ('$.\"llm\".\"token_count\".\"prompt\"', '$.\"llm\".\"token_count\".\"completion\"')\n",
      "2025-01-21 00:01:44,364 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='3be8647b87d8' WHERE alembic_version.version_num = '10460e46d750'\n",
      "2025-01-21 00:01:44,364 INFO sqlalchemy.engine.Engine [generated in 0.00008s] ()\n",
      "2025-01-21 00:01:44,364 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE user_roles (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tCONSTRAINT pk_user_roles PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,365 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,365 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_user_roles_name ON user_roles (name)\n",
      "2025-01-21 00:01:44,365 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,366 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE users (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_role_id INTEGER NOT NULL, \n",
      "\tusername VARCHAR NOT NULL, \n",
      "\temail VARCHAR NOT NULL, \n",
      "\tprofile_picture_url VARCHAR, \n",
      "\tpassword_hash BLOB, \n",
      "\tpassword_salt BLOB, \n",
      "\treset_password BOOLEAN NOT NULL, \n",
      "\toauth2_client_id VARCHAR, \n",
      "\toauth2_user_id VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT \"ck_users_`password_hash_and_salt`\" CHECK ((password_hash IS NULL) = (password_salt IS NULL)), \n",
      "\tCONSTRAINT \"ck_users_`oauth2_client_id_and_user_id`\" CHECK ((oauth2_client_id IS NULL) = (oauth2_user_id IS NULL)), \n",
      "\tCONSTRAINT \"ck_users_`exactly_one_auth_method`\" CHECK ((password_hash IS NULL) != (oauth2_client_id IS NULL)), \n",
      "\tCONSTRAINT uq_users_oauth2_client_id_oauth2_user_id UNIQUE (oauth2_client_id, oauth2_user_id), \n",
      "\tCONSTRAINT fk_users_user_role_id_user_roles FOREIGN KEY(user_role_id) REFERENCES user_roles (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,366 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-21 00:01:44,366 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_oauth2_client_id ON users (oauth2_client_id)\n",
      "2025-01-21 00:01:44,366 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_user_role_id ON users (user_role_id)\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_oauth2_user_id ON users (oauth2_user_id)\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_users_username ON users (username)\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_users_email ON users (email)\n",
      "2025-01-21 00:01:44,367 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-21 00:01:44,368 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE password_reset_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT fk_password_reset_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,368 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-21 00:01:44,368 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_password_reset_tokens_user_id ON password_reset_tokens (user_id)\n",
      "2025-01-21 00:01:44,368 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,368 INFO sqlalchemy.engine.Engine CREATE INDEX ix_password_reset_tokens_expires_at ON password_reset_tokens (expires_at)\n",
      "2025-01-21 00:01:44,368 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,369 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE refresh_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT fk_refresh_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,370 INFO sqlalchemy.engine.Engine [no key 0.00013s] ()\n",
      "2025-01-21 00:01:44,370 INFO sqlalchemy.engine.Engine CREATE INDEX ix_refresh_tokens_expires_at ON refresh_tokens (expires_at)\n",
      "2025-01-21 00:01:44,370 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-21 00:01:44,370 INFO sqlalchemy.engine.Engine CREATE INDEX ix_refresh_tokens_user_id ON refresh_tokens (user_id)\n",
      "2025-01-21 00:01:44,370 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-21 00:01:44,371 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE access_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\trefresh_token_id INTEGER, \n",
      "\tCONSTRAINT fk_access_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_access_tokens_refresh_token_id_refresh_tokens FOREIGN KEY(refresh_token_id) REFERENCES refresh_tokens (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,371 INFO sqlalchemy.engine.Engine [no key 0.00011s] ()\n",
      "2025-01-21 00:01:44,371 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_access_tokens_refresh_token_id ON access_tokens (refresh_token_id)\n",
      "2025-01-21 00:01:44,371 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,372 INFO sqlalchemy.engine.Engine CREATE INDEX ix_access_tokens_expires_at ON access_tokens (expires_at)\n",
      "2025-01-21 00:01:44,372 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,372 INFO sqlalchemy.engine.Engine CREATE INDEX ix_access_tokens_user_id ON access_tokens (user_id)\n",
      "2025-01-21 00:01:44,372 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-21 00:01:44,372 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE api_keys (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP, \n",
      "\tCONSTRAINT fk_api_keys_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,372 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,373 INFO sqlalchemy.engine.Engine CREATE INDEX ix_api_keys_user_id ON api_keys (user_id)\n",
      "2025-01-21 00:01:44,373 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,373 INFO sqlalchemy.engine.Engine CREATE INDEX ix_api_keys_expires_at ON api_keys (expires_at)\n",
      "2025-01-21 00:01:44,373 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,373 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='cd164e83824f' WHERE alembic_version.version_num = '3be8647b87d8'\n",
      "2025-01-21 00:01:44,373 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-21 00:01:44,374 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE project_sessions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tsession_id VARCHAR NOT NULL, \n",
      "\tproject_id INTEGER NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_project_sessions PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_project_sessions_session_id UNIQUE (session_id), \n",
      "\tCONSTRAINT fk_project_sessions_project_id_projects FOREIGN KEY(project_id) REFERENCES projects (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,374 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,374 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_project_id ON project_sessions (project_id)\n",
      "2025-01-21 00:01:44,374 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,375 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_start_time ON project_sessions (start_time)\n",
      "2025-01-21 00:01:44,375 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,375 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_end_time ON project_sessions (end_time)\n",
      "2025-01-21 00:01:44,375 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"traces\")\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"traces\")\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-21 00:01:44,376 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"traces\")\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_project_rowid\")\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_start_time\")\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"traces\")\n",
      "2025-01-21 00:01:44,378 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_project_rowid\")\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_start_time\")\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"sqlite_autoindex_traces_1\")\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-21 00:01:44,379 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-21 00:01:44,380 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"projects\")\n",
      "2025-01-21 00:01:44,380 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,380 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-21 00:01:44,380 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-21 00:01:44,380 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"projects\")\n",
      "2025-01-21 00:01:44,380 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine PRAGMA temp.foreign_key_list(\"projects\")\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"projects\")\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"projects\")\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"projects\")\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"sqlite_autoindex_projects_1\")\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-21 00:01:44,381 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-21 00:01:44,383 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE _alembic_tmp_traces (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tproject_rowid INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tproject_session_rowid INTEGER, \n",
      "\tCONSTRAINT pk_traces PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_traces_project_rowid_projects FOREIGN KEY(project_rowid) REFERENCES projects (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_traces_trace_id UNIQUE (trace_id), \n",
      "\tCONSTRAINT fk_traces_project_session_rowid_project_sessions FOREIGN KEY(project_session_rowid) REFERENCES project_sessions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-21 00:01:44,383 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-21 00:01:44,384 INFO sqlalchemy.engine.Engine INSERT INTO _alembic_tmp_traces (id, project_rowid, trace_id, start_time, end_time) SELECT traces.id, traces.project_rowid, traces.trace_id, traces.start_time, traces.end_time \n",
      "FROM traces\n",
      "2025-01-21 00:01:44,385 INFO sqlalchemy.engine.Engine [generated in 0.00011s] ()\n",
      "2025-01-21 00:01:44,385 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE traces\n",
      "2025-01-21 00:01:44,385 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,385 INFO sqlalchemy.engine.Engine ALTER TABLE _alembic_tmp_traces RENAME TO traces\n",
      "2025-01-21 00:01:44,385 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,386 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_start_time ON traces (start_time)\n",
      "2025-01-21 00:01:44,386 INFO sqlalchemy.engine.Engine [no key 0.00010s] ()\n",
      "2025-01-21 00:01:44,386 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_rowid ON traces (project_rowid)\n",
      "2025-01-21 00:01:44,386 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-21 00:01:44,387 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_session_rowid ON traces (project_session_rowid)\n",
      "2025-01-21 00:01:44,387 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-21 00:01:44,387 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='4ded9e43755f' WHERE alembic_version.version_num = 'cd164e83824f'\n",
      "2025-01-21 00:01:44,387 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-21 00:01:44,388 INFO sqlalchemy.engine.Engine COMMIT\n",
      "---------------------------\n",
      "‚úÖ Migrations completed in 0.141 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:6006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ïî‚ïù\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïó\n",
      "‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù v7.7.1\n",
      "\n",
      "|\n",
      "|  üåé Join our Community üåé\n",
      "|  https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\n",
      "|\n",
      "|  ‚≠êÔ∏è Leave us a Star ‚≠êÔ∏è\n",
      "|  https://github.com/Arize-ai/phoenix\n",
      "|\n",
      "|  üìö Documentation üìö\n",
      "|  https://docs.arize.com/phoenix\n",
      "|\n",
      "|  üöÄ Phoenix Server üöÄ\n",
      "|  Phoenix UI: http://0.0.0.0:6006\n",
      "|  Authentication: False\n",
      "|  Websockets: True\n",
      "|  Log traces:\n",
      "|    - gRPC: http://0.0.0.0:4317\n",
      "|    - HTTP: http://0.0.0.0:6006/v1/traces\n",
      "|  Storage: sqlite:////root/.phoenix/phoenix.db\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: ../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt\n",
      "INFO:lightrag:Load KV llm_response_cache with 0 data\n",
      "INFO:lightrag:Load KV full_docs with 0 data\n",
      "INFO:lightrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_chunks.json'} 0 data\n",
      "INFO:lightrag:Loaded document status storage with 0 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm import gpt_4o_mini_complete\n",
    "import nano_vectordb\n",
    "\n",
    "# below two lines required if running in a jupyter notebook to handle the async nature of rag.insert()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=gpt_4o_mini_complete\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Processing 1 new unique documents\n",
      "Processing batch 1:   0%|          | 0/1 [00:00<?, ?it/s]INFO:lightrag:Inserting 5 vectors to chunks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.07s/batch]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†ô Processed 1 chunks, 4 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†π Processed 2 chunks, 22 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†∏ Processed 3 chunks, 40 entities(duplicated), 28 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     172.17.0.1:40806 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:40834 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:40822 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:40822 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:40834 - \"POST /graphql HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†º Processed 4 chunks, 61 entities(duplicated), 43 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†¥ Processed 5 chunks, 90 entities(duplicated), 68 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:41<00:00,  8.35s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:00<00:00, 24367.56entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 16139.82relationship/s]\n",
      "INFO:lightrag:Inserting 79 vectors to entities\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.51batch/s]\n",
      "INFO:lightrag:Inserting 63 vectors to relationships\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.33batch/s]\n",
      "INFO:lightrag:Writing graph with 83 nodes, 63 edges\n",
      "Processing batch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:46<00:00, 46.59s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(local_file_path) as f:\n",
    "    rag.insert(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## APPROACH 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:kw_prompt result:\n",
      "INFO:lightrag:Using hybrid mode for query processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"high_level_keywords\": [\"King Leopold\", \"Evacuation of Dunkirk\", \"Historical role\"],\n",
      "  \"low_level_keywords\": [\"World War II\", \"Dunkirk evacuation\", \"Belgium\", \"Military leadership\", \"Historical events\"]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Local query uses 60 entites, 57 relations, 3 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Global query uses 72 entites, 60 relations, 4 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Leopold of Belgium played a pivotal role during the evacuation of Dunkirk, significantly influencing the dynamics of the Allied forces' efforts during World War II. His decisions directly impacted the military strategies of both the Belgian and Allied armies.\n",
      "\n",
      "At the outset of the German invasion, King Leopold had appealed to the Allies for assistance, leading to the deployment of British and French forces to Belgian territory. The initial intent was to coordinate a defense against the rapidly advancing German Army. However, this situation changed dramatically when King Leopold unilaterally decided to surrender the Belgian Army to the German Command without prior consultation with his advisers or the Allies. This decision took place shortly after the German forces penetrated deeper into Belgium, which left the British and French troops at a strategic disadvantage.\n",
      "\n",
      "The surrender of the Belgian Army meant that the British forces were compelled to cover a flank of more than 30 miles to the sea, significantly straining their defensive capabilities. The Allied forces were then faced with increased pressure as they found themselves encircled and heavily attacked on all sides. King Leopold's choice to capitulate ultimately exposed the Allied left flank and limited their ability to maintain coherent defensive lines.\n",
      "\n",
      "The effects of his actions were felt deeply during the evacuation operations at Dunkirk. While the Allied troops, especially the British Expeditionary Force, carried out the challenging task of retreating under fire, they did so with diminished support as a result of losing the cooperation of Belgium's military strength. \n",
      "\n",
      "In summary, King Leopold‚Äôs decision to surrender had grave implications for the Allied military strategy during the evacuation of Dunkirk, illustrating the complex interplay of leadership and fate during this critical moment in the war. His actions are often viewed critically in historical contexts, highlighting the profound consequences that national leadership decisions can have during wartime.\n"
     ]
    }
   ],
   "source": [
    "# Perform hybrid search\n",
    "print(\"\\n## APPROACH 4\\n\")\n",
    "print(rag.query(RAG_QUERY, param=QueryParam(mode=\"hybrid\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Graph\n",
    "\n",
    "- graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def create_interactive_visualization(graphml_file, output_file):\n",
    "    # Load the GraphML file\n",
    "    G = nx.read_graphml(graphml_file)\n",
    "    \n",
    "    # Create Pyvis network\n",
    "    net = Network(height='900px', width='100%', bgcolor='#ffffff', \n",
    "                 font_color='black', notebook=False)\n",
    "    \n",
    "    # Define color scheme for entity types\n",
    "    entity_colors = {\n",
    "        'PERSON': '#e41a1c',        # Bright red\n",
    "        'ORGANIZATION': '#377eb8',   # Blue\n",
    "        'GEO': '#4daf4a',           # Green\n",
    "        'EVENT': '#984ea3',         # Purple\n",
    "        'CONCEPT': '#ff7f00',       # Orange\n",
    "        'TECHNOLOGY': '#a65628',     # Brown\n",
    "        'CATEGORY': '#f781bf',      # Pink\n",
    "        'NUMBER': '#999999',        # Gray\n",
    "        'UNKNOWN': '#808080'        # Dark Gray\n",
    "    }\n",
    "    \n",
    "    # Add nodes with colors before adding edges\n",
    "    for node_id, node_data in G.nodes(data=True):\n",
    "        # Get entity type (removing quotes if present)\n",
    "        entity_type = node_data.get('entity_type', 'UNKNOWN').replace('\"', '')\n",
    "        color = entity_colors.get(entity_type, '#808080')\n",
    "        \n",
    "        # Create hover text\n",
    "        hover_info = f\"\"\"\n",
    "        Entity: {node_id}\n",
    "        Type: {entity_type}\n",
    "        Description: {node_data.get('description', 'N/A')}\n",
    "        Source ID: {node_data.get('source_id', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add node with properties\n",
    "        net.add_node(node_id, \n",
    "                    title=hover_info,\n",
    "                    color=color,\n",
    "                    size=30)\n",
    "\n",
    "    # Add edges\n",
    "    for source, target, edge_data in G.edges(data=True):\n",
    "        weight = edge_data.get('weight', 1)\n",
    "        description = edge_data.get('description', '')\n",
    "        \n",
    "        hover_info = f\"\"\"\n",
    "        Weight: {weight}\n",
    "        Description: {description}\n",
    "        Keywords: {edge_data.get('keywords', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        net.add_edge(source, target,\n",
    "                    title=hover_info,\n",
    "                    width=float(weight),\n",
    "                    color={'color': '#666666', 'highlight': '#ff0000'})\n",
    "\n",
    "    # Rest of your physics and legend code remains the same\n",
    "    physics_options = {\n",
    "        \"physics\": {\n",
    "            \"forceAtlas2Based\": {\n",
    "                \"gravitationalConstant\": -100,\n",
    "                \"centralGravity\": 0.01,\n",
    "                \"springLength\": 200,\n",
    "                \"springConstant\": 0.08,\n",
    "                \"damping\": 0.4,\n",
    "                \"avoidOverlap\": 1\n",
    "            },\n",
    "            \"solver\": \"forceAtlas2Based\",\n",
    "            \"stabilization\": {\n",
    "                \"enabled\": True,\n",
    "                \"iterations\": 1000,\n",
    "                \"updateInterval\": 25\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    net.set_options(json.dumps(physics_options))\n",
    "    \n",
    "    # Save and add legend\n",
    "    net.write_html(output_file)\n",
    "    \n",
    "    # Add legend HTML\n",
    "    legend_html = \"\"\"\n",
    "    <div style=\"position: absolute; top: 10px; left: 10px; background-color: rgba(255, 255, 255, 0.9); \n",
    "                padding: 10px; border-radius: 5px; border: 1px solid #ccc;\">\n",
    "        <h3>Entity Types</h3>\n",
    "        <ul style=\"list-style-type: none; padding: 0;\">\n",
    "    \"\"\"\n",
    "    \n",
    "    for entity_type, color in entity_colors.items():\n",
    "        legend_html += f\"\"\"\n",
    "            <li style=\"margin: 5px 0;\">\n",
    "                <span style=\"display: inline-block; width: 20px; height: 20px; \n",
    "                           background-color: {color}; border-radius: 50%; margin-right: 5px;\"></span>\n",
    "                {entity_type}\n",
    "            </li>\n",
    "        \"\"\"\n",
    "    \n",
    "    legend_html += \"\"\"\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    content = content.replace('</body>', f'{legend_html}</body>')\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     172.17.0.1:43644 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:43672 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:43660 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:43660 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:43672 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:41320 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:41334 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:41350 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:49226 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:49234 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:49242 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:39028 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:39036 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:39040 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:44652 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:44660 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:44664 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:34306 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:34310 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:34316 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:33132 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:33136 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:33150 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:57524 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:57530 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:57534 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:58040 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:58042 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:58044 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:48146 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:48152 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:48168 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:40744 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:40746 - \"POST /graphql HTTP/1.1\" 200 OK\n",
      "INFO:     172.17.0.1:40760 - \"POST /graphql HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Generate Visualization\n",
    "create_interactive_visualization(GRAPHML_FILE, str(PYVIS_HTML_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Telemetry data\n",
    "\n",
    "- Access the Arize Phoenix UI at [http://localhost:6006](http://localhost:6006)\n",
    "- both LLM inference and embedding telemetry information is captured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç LightRAG Validation with Arize Phoenix\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook provides one approach for validating and monitoring LightRAG's interaction with LLMs and embedding models -- leveraging [Arize Phoenix](https://docs.arize.com/phoenix/tracing/llm-traces-1) it provides insight into what is a very complex data ingestion pipeline.\n",
    "\n",
    "It will also make the concepts covered in the LightRAG paper more tangible.\n",
    "\n",
    "### Purpose\n",
    "- **System Monitoring**: Validate LightRAG's integration with telemetry pipelines to ensure robust tracking of model inference and embedding use.\n",
    "- **Performance Tuning**: Identify bottlenecks and optimize configurations using insights from telemetry data.\n",
    "- **Proactive Debugging**: Quickly detect and resolve anomalies through real-time analysis.\n",
    "\n",
    "### Key Features\n",
    "- **Dockerized Deployment**: Simplifies setup with preconfigured Docker containers for Arize Phoenix.\n",
    "- **Telemetry Integration**: Supports integration with external systems through use of OpenTelemetry standard to provide detailed system traces.\n",
    "- **Customizable Dashboards**: Enables interactive exploration of model metrics and error logs.\n",
    "\n",
    "### Usage Instructions\n",
    "1. **Setup**: \n",
    "    - Install required dependencies:\n",
    "      ```bash\n",
    "      pip install arize-phoenix-otel\n",
    "      ```\n",
    "    - Run the Docker container for Arize Phoenix:\n",
    "      ```bash\n",
    "      docker run -p 6006:6006 -p 4317:4317 --rm arizephoenix/phoenix:latest\n",
    "      ```\n",
    "\n",
    "2. **Execute the Notebook**: Follow the provided steps in the notebook to validate your LightRAG setup against telemetry data.\n",
    "\n",
    "3. **Explore Metrics**:\n",
    "    - Access the Phoenix UI at [http://localhost:6006](http://localhost:6006).\n",
    "    - Analyze detailed traces, latencies, and throughput metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
