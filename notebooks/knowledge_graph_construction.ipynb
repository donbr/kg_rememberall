{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4c4316-f9f8-416d-ac33-8f52fee1be45",
   "metadata": {},
   "source": [
    "# Part 1: Construct a KG from unstructured data\n",
    "\n",
    "This notebook illustrates the internal steps for the implementation of an NLP pipeline for constructing _knowledge graphs_ from unstructured data sources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1438b6-9e0d-4fea-872e-2a9d3b7631c8",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462fdb2f-ce46-4c57-97d1-c0729ac0f02e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:03.811216Z",
     "iopub.status.busy": "2024-08-12T20:28:03.810986Z",
     "iopub.status.idle": "2024-08-12T20:28:05.777057Z",
     "shell.execute_reply": "2024-08-12T20:28:05.776713Z",
     "shell.execute_reply.started": "2024-08-12T20:28:03.811198Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image, SVG\n",
    "\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "import os\n",
    "import typing\n",
    "import warnings\n",
    "\n",
    "from gliner_spacy.pipeline import GlinerSpacy\n",
    "from icecream import ic\n",
    "from pydantic import BaseModel\n",
    "from pyinstrument import Profiler\n",
    "import glirel\n",
    "import matplotlib\n",
    "import matplotlib.colors\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pyvis\n",
    "import spacy\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bde75b-ef58-4f98-b581-228f89339a91",
   "metadata": {},
   "source": [
    "Override specific Hugging Face error messages, since `transformers` and `tokenizers` have noisy logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8267417-8b99-4574-8c12-f71129fc99da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:05.777688Z",
     "iopub.status.busy": "2024-08-12T20:28:05.777468Z",
     "iopub.status.idle": "2024-08-12T20:28:05.779615Z",
     "shell.execute_reply": "2024-08-12T20:28:05.779331Z",
     "shell.execute_reply.started": "2024-08-12T20:28:05.777678Z"
    }
   },
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d04b7-d90b-48f2-8b0b-eae64bdfcc9c",
   "metadata": {},
   "source": [
    "Show a watermark of the OS, hardware, language environment, and dependent library versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675bc95-8e74-46f4-933e-a606c5e2c64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:05.779992Z",
     "iopub.status.busy": "2024-08-12T20:28:05.779923Z",
     "iopub.status.idle": "2024-08-12T20:28:05.801772Z",
     "shell.execute_reply": "2024-08-12T20:28:05.801462Z",
     "shell.execute_reply.started": "2024-08-12T20:28:05.779985Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455b153-9fa2-4e4d-a7ed-b039b4d0ac96",
   "metadata": {},
   "source": [
    "Start the stochastic stack trace profiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9f674a-d96d-4cd3-86e3-e0129ca20772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:05.802417Z",
     "iopub.status.busy": "2024-08-12T20:28:05.802336Z",
     "iopub.status.idle": "2024-08-12T20:28:05.805180Z",
     "shell.execute_reply": "2024-08-12T20:28:05.804552Z",
     "shell.execute_reply.started": "2024-08-12T20:28:05.802406Z"
    }
   },
   "outputs": [],
   "source": [
    "profiler: Profiler = Profiler()\n",
    "profiler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7159a-d1f3-4616-8513-6b3f1185b874",
   "metadata": {},
   "source": [
    "Define the model selections and parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ffd42e-2279-4112-8c31-5d02a111f0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:05.806239Z",
     "iopub.status.busy": "2024-08-12T20:28:05.806072Z",
     "iopub.status.idle": "2024-08-12T20:28:05.811025Z",
     "shell.execute_reply": "2024-08-12T20:28:05.810578Z",
     "shell.execute_reply.started": "2024-08-12T20:28:05.806224Z"
    }
   },
   "outputs": [],
   "source": [
    "CHUNK_SIZE: int = 1024\n",
    "\n",
    "GLINER_MODEL: str = \"urchade/gliner_small-v2.1\"\n",
    "\n",
    "NER_LABELS: typing.List[str] = [\n",
    "    \"PERSON\",        # For military/political leaders like Churchill, General Weygand, King Leopold\n",
    "    \"ORG\",          # For organizations like Royal Air Force, Royal Navy, British Expeditionary Force  \n",
    "    \"GPE\",          # For geopolitical entities like Belgium, France, England\n",
    "    \"LOC\",          # For locations like beaches, channels\n",
    "    \"FACILITY\",     # For facilities like ports, fortifications\n",
    "    \"DATE\",         # For temporal references\n",
    "    \"EVENT\",        # For battles and military operations\n",
    "    \"PRODUCT\",      # For military equipment/vehicles (e.g. Spitfire, Hurricane)\n",
    "    \"NORP\",         # For nationalities/religious/political groups (e.g. German, British, French)\n",
    "]\n",
    "\n",
    "RE_LABELS: dict = {\n",
    "    \"glirel_labels\": {\n",
    "        \"commands\": {\n",
    "            \"allowed_head\": [\"PERSON\"], \n",
    "            \"allowed_tail\": [\"ORG\"]\n",
    "        },\n",
    "        \"located_in\": {\n",
    "            \"allowed_head\": [\"FACILITY\", \"LOC\"], \n",
    "            \"allowed_tail\": [\"GPE\"]\n",
    "        },\n",
    "        \"member_of\": {\n",
    "            \"allowed_head\": [\"PERSON\"],\n",
    "            \"allowed_tail\": [\"ORG\"]\n",
    "        },\n",
    "        \"affiliated_with\": {\n",
    "            \"allowed_head\": [\"ORG\"],\n",
    "            \"allowed_tail\": [\"GPE\"]\n",
    "        },\n",
    "        \"participated_in\": {\n",
    "            \"allowed_head\": [\"ORG\", \"PERSON\"],\n",
    "            \"allowed_tail\": [\"EVENT\"] \n",
    "        },\n",
    "        \"occurred_at\": {\n",
    "            \"allowed_head\": [\"EVENT\"],\n",
    "            \"allowed_tail\": [\"LOC\", \"GPE\", \"FACILITY\"]\n",
    "        },\n",
    "        \"occurred_on\": {\n",
    "            \"allowed_head\": [\"EVENT\"],\n",
    "            \"allowed_tail\": [\"DATE\"]\n",
    "        },\n",
    "        \"leader_of\": {\n",
    "            \"allowed_head\": [\"PERSON\"],\n",
    "            \"allowed_tail\": [\"GPE\", \"ORG\"]\n",
    "        },\n",
    "        \"allied_with\": {\n",
    "            \"allowed_head\": [\"GPE\"],\n",
    "            \"allowed_tail\": [\"GPE\"]\n",
    "        },\n",
    "        \"no_relation\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "SPACY_MODEL: str = \"en_core_web_md\"\n",
    "\n",
    "STOP_WORDS: typing.Set[ str ] = set([\n",
    "    \"PRON.it\",\n",
    "    \"PRON.that\",\n",
    "    \"PRON.they\",\n",
    "    \"PRON.those\",\n",
    "    \"PRON.we\",\n",
    "    \"PRON.which\",\n",
    "    \"PRON.who\",\n",
    "])\n",
    "\n",
    "TR_ALPHA: float = 0.85\n",
    "TR_LOOKBACK: int = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8fb60-8b0b-4238-8ef7-e0ff79234387",
   "metadata": {},
   "source": [
    "Load the models for `spaCy`, `GLiNER`, `GLiREL` -- this may take several minutes when run the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a436ea7-8274-4b2d-8e6b-c819bdb294da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:05.813839Z",
     "iopub.status.busy": "2024-08-12T20:28:05.813627Z",
     "iopub.status.idle": "2024-08-12T20:28:18.153663Z",
     "shell.execute_reply": "2024-08-12T20:28:18.153119Z",
     "shell.execute_reply.started": "2024-08-12T20:28:05.813823Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp: spacy.Language = spacy.load(SPACY_MODEL)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    nlp.add_pipe(\n",
    "        \"gliner_spacy\",\n",
    "        config = {\n",
    "            \"gliner_model\": GLINER_MODEL,\n",
    "            \"labels\": NER_LABELS,\n",
    "            \"chunk_size\": CHUNK_SIZE,\n",
    "            \"style\": \"ent\",\n",
    "        },\n",
    "    )\n",
    "        \n",
    "    nlp.add_pipe(\n",
    "        \"glirel\",\n",
    "        after = \"ner\",\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68eb24-2de1-4821-b68f-3ec6296dd434",
   "metadata": {},
   "source": [
    "Define the global data structures -- which need to be reset for every run, not for each chunk iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8428135c-6560-482d-a470-dfeb49a5ac55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:18.154637Z",
     "iopub.status.busy": "2024-08-12T20:28:18.154330Z",
     "iopub.status.idle": "2024-08-12T20:28:18.157308Z",
     "shell.execute_reply": "2024-08-12T20:28:18.156809Z",
     "shell.execute_reply.started": "2024-08-12T20:28:18.154619Z"
    }
   },
   "outputs": [],
   "source": [
    "graph: nx.Graph = nx.Graph()\n",
    "known_lemma: typing.List[ str ] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45acde6-2fc4-4a07-b43e-ce240070b3e1",
   "metadata": {},
   "source": [
    "## Parse one text chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2f9d4-8ea4-4260-984b-a5439ede386c",
   "metadata": {},
   "source": [
    "Define an input text chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb077276-ae16-4aff-9ede-63ccdea9a7ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:18.158068Z",
     "iopub.status.busy": "2024-08-12T20:28:18.157929Z",
     "iopub.status.idle": "2024-08-12T20:28:18.187110Z",
     "shell.execute_reply": "2024-08-12T20:28:18.186793Z",
     "shell.execute_reply.started": "2024-08-12T20:28:18.158054Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextChunk (BaseModel):\n",
    "    uid: int\n",
    "    url: str\n",
    "    text: str\n",
    "    \n",
    "SAMPLE_CHUNK: TextChunk = TextChunk(\n",
    "    uid = 1,\n",
    "    url = \"https://raw.githubusercontent.com/donbr/kg_rememberall/refs/heads/main/references/winston_churchill_we_shall_fight_speech_june_1940.txt\",\n",
    "    text = \"\"\"\n",
    "I have, myself, full confidence that if all do their duty, if nothing is neglected, and if the best arrangements are made, as they are being made, we shall prove ourselves once again able to defend our Island home, to ride out the storm of war, and to outlive the menace of tyranny, if necessary for years, if necessary alone. At any rate, that is what we are going to try to do. That is the resolve of His Majesty’s Government-every man of them. That is the will of Parliament and the nation. The British Empire and the French Republic, linked together in their cause and in their need, will defend to the death their native soil, aiding each other like good comrades to the utmost of their strength. Even though large tracts of Europe and many old and famous States have fallen or may fall into the grip of the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail. We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God’s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.\n",
    "    \"\"\".strip(),\n",
    ")\n",
    "\n",
    "chunk: TextChunk = SAMPLE_CHUNK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f97d2-96eb-464a-97d7-9561d4db8528",
   "metadata": {},
   "source": [
    "Parse the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4871d9-8113-4e31-bb28-94325f144bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:18.187790Z",
     "iopub.status.busy": "2024-08-12T20:28:18.187658Z",
     "iopub.status.idle": "2024-08-12T20:28:19.418640Z",
     "shell.execute_reply": "2024-08-12T20:28:19.418255Z",
     "shell.execute_reply.started": "2024-08-12T20:28:18.187760Z"
    }
   },
   "outputs": [],
   "source": [
    "doc: spacy.tokens.doc.Doc = list(\n",
    "    nlp.pipe(\n",
    "        [( chunk.text, RE_LABELS )],\n",
    "        as_tuples = True,\n",
    "    )\n",
    ")[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943baa84-74e6-40f4-95f2-dfe3034a39eb",
   "metadata": {},
   "source": [
    "Visualize the `spaCy` parse and `GLiNER` _named entity recognition_ results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3da3f0-bb24-46b2-a818-fc47eedfd925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:19.419409Z",
     "iopub.status.busy": "2024-08-12T20:28:19.419276Z",
     "iopub.status.idle": "2024-08-12T20:28:19.505543Z",
     "shell.execute_reply": "2024-08-12T20:28:19.505194Z",
     "shell.execute_reply.started": "2024-08-12T20:28:19.419393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    spacy.displacy.render(\n",
    "        sent,\n",
    "        style = \"ent\",\n",
    "        jupyter = True,\n",
    "    )\n",
    "\n",
    "    parse_svg: str = spacy.displacy.render(\n",
    "        sent,\n",
    "        style = \"dep\",\n",
    "        jupyter = True,\n",
    "    )\n",
    "\n",
    "    display(SVG(parse_svg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b4ea1-d8f0-4562-b4f1-87d2887c1d43",
   "metadata": {},
   "source": [
    "## Layer 1: construct a lexical graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268f061-c64d-42dc-a768-072ec9931e36",
   "metadata": {},
   "source": [
    "Scan the document tokens to add lemmas to the _textgraph_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87ac9e-effb-4184-94ef-8973f7ee8e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:19.506397Z",
     "iopub.status.busy": "2024-08-12T20:28:19.506201Z",
     "iopub.status.idle": "2024-08-12T20:28:20.136690Z",
     "shell.execute_reply": "2024-08-12T20:28:20.135679Z",
     "shell.execute_reply.started": "2024-08-12T20:28:19.506379Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    node_seq: typing.List[ int ] = []\n",
    "    ic(sent)\n",
    "\n",
    "    for tok in sent:\n",
    "        text: str = tok.text.strip()\n",
    "        \n",
    "        if tok.pos_ in [ \"NOUN\", \"PROPN\" ]:\n",
    "            key: str = tok.pos_ + \".\" + tok.lemma_.strip().lower()\n",
    "            print(tok.i, key, tok.text.strip())\n",
    "\n",
    "            if key not in known_lemma:\n",
    "                # create a new node\n",
    "                known_lemma.append(key)\n",
    "                node_id: int = known_lemma.index(key)\n",
    "                node_seq.append(node_id)\n",
    "\n",
    "                graph.add_node(\n",
    "                    node_id,\n",
    "                    key = key,\n",
    "                    kind = \"Lemma\",\n",
    "                    pos = tok.pos_,\n",
    "                    text = text,\n",
    "                    chunk = chunk.uid,\n",
    "                    count = 1,\n",
    "                )\n",
    "            else:\n",
    "                # link to an existing node, adding weight\n",
    "                node_id = known_lemma.index(key)\n",
    "                node_seq.append(node_id)\n",
    "\n",
    "                node: dict = graph.nodes[node_id]\n",
    "                node[\"count\"] += 1\n",
    "\n",
    "    # create the textrank edges\n",
    "    ic(node_seq)\n",
    "\n",
    "    for hop in range(TR_LOOKBACK):\n",
    "        for node_id, node in enumerate(node_seq[: -1 - hop]):            \n",
    "            neighbor: int = node_seq[hop + node_id + 1]\n",
    "            graph.add_edge(\n",
    "                node,\n",
    "                neighbor,\n",
    "                rel = \"FOLLOWS_LEXICALLY\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676db9a-142e-42b9-916c-853a0f75ae0a",
   "metadata": {},
   "source": [
    "Keep track of the sentence numbers, which we'll use later for entity co-occurrence links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7eaa2e9-83ca-4e15-a38a-ce3659c373b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:20.137897Z",
     "iopub.status.busy": "2024-08-12T20:28:20.137774Z",
     "iopub.status.idle": "2024-08-12T20:28:20.140871Z",
     "shell.execute_reply": "2024-08-12T20:28:20.140374Z",
     "shell.execute_reply.started": "2024-08-12T20:28:20.137884Z"
    }
   },
   "outputs": [],
   "source": [
    "sent_map: typing.Dict[ spacy.tokens.span.Span, int ] = {}\n",
    "\n",
    "for sent_id, sent in enumerate(doc.sents):\n",
    "    sent_map[sent] = sent_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba51a1f7-517b-4bf9-8153-c41cd15b952d",
   "metadata": {},
   "source": [
    "## Layer 2: overlay entities onto the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8bc6b8-332c-409b-80d4-9f9f7bc9286e",
   "metadata": {},
   "source": [
    "Classify spans as potential entities.\n",
    "\n",
    "Note that if we'd run [_entity resolution_](https://neo4j.com/developer-blog/entity-resolved-knowledge-graphs/) previously from _structured_ or _semi-structured_ data sources to generate a \"backbone\" for the knowledge graph, then we use the contextualized _surface forms_ from that phase to perform _entity linking_ on the entities extracted here from _unstructured_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5b8720-3a08-4e52-9911-959c5e34b956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:20.141597Z",
     "iopub.status.busy": "2024-08-12T20:28:20.141493Z",
     "iopub.status.idle": "2024-08-12T20:28:20.146243Z",
     "shell.execute_reply": "2024-08-12T20:28:20.145805Z",
     "shell.execute_reply.started": "2024-08-12T20:28:20.141583Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass(order=False, frozen=False)\n",
    "class Entity:\n",
    "    loc: typing.Tuple[ int ]\n",
    "    key: str\n",
    "    text: str\n",
    "    label: str\n",
    "    chunk_id: int\n",
    "    sent_id: int\n",
    "    span: spacy.tokens.span.Span\n",
    "    node: typing.Optional[ int ] = None\n",
    "\n",
    "\n",
    "span_decoder: typing.Dict[ tuple, Entity ] = {}\n",
    "\n",
    "\n",
    "def make_entity (\n",
    "    span: spacy.tokens.span.Span,\n",
    "    chunk: TextChunk,\n",
    "    ) -> Entity:\n",
    "    \"\"\"\n",
    "Instantiate one `Entity` dataclass object, adding it to the working \"vocabulary\".\n",
    "    \"\"\"\n",
    "    key: str = \" \".join([\n",
    "        tok.pos_ + \".\" + tok.lemma_.strip().lower()\n",
    "        for tok in span\n",
    "    ])\n",
    "    \n",
    "    ent: Entity = Entity(\n",
    "        ( span.start, span.end, ),\n",
    "        key,\n",
    "        span.text,\n",
    "        span.label_,\n",
    "        chunk.uid,\n",
    "        sent_map[span.sent],\n",
    "        span,\n",
    "    )\n",
    "\n",
    "    if ent.loc not in span_decoder:\n",
    "        span_decoder[ent.loc] = ent\n",
    "        ic(ent)\n",
    "\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332266a3-19d2-4cd2-adfd-5c04b55539db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:20.147285Z",
     "iopub.status.busy": "2024-08-12T20:28:20.147152Z",
     "iopub.status.idle": "2024-08-12T20:28:23.393988Z",
     "shell.execute_reply": "2024-08-12T20:28:23.393642Z",
     "shell.execute_reply.started": "2024-08-12T20:28:20.147272Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for span in doc.ents:\n",
    "    make_entity(span, chunk)\n",
    "\n",
    "for span in doc.noun_chunks:\n",
    "    make_entity(span, chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be16df-58d3-4355-bf0f-46365a2ca387",
   "metadata": {},
   "source": [
    "Overlay the inferred entity spans atop the base layer constructed by _textgraph_ analysis of the `spaCy` parse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1a525c1-7f62-401a-ab91-81ef13f325a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:23.394749Z",
     "iopub.status.busy": "2024-08-12T20:28:23.394619Z",
     "iopub.status.idle": "2024-08-12T20:28:23.398716Z",
     "shell.execute_reply": "2024-08-12T20:28:23.398457Z",
     "shell.execute_reply.started": "2024-08-12T20:28:23.394737Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_entity (\n",
    "    ent: Entity,\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "Link one `Entity` into the existing graph.\n",
    "    \"\"\"\n",
    "    if ent.key not in known_lemma:\n",
    "        # add a new Entity node to the graph and link to its component Lemma nodes\n",
    "        known_lemma.append(ent.key)\n",
    "        node_id: int = known_lemma.index(ent.key)\n",
    "        \n",
    "        graph.add_node(\n",
    "            node_id,\n",
    "            key = ent.key,\n",
    "            kind = \"Entity\",\n",
    "            label = ent.label,\n",
    "            pos = \"NP\",\n",
    "            text = ent.text,\n",
    "            chunk = ent.chunk_id,\n",
    "            count = 1,\n",
    "        )\n",
    "\n",
    "        for tok in ent.span:\n",
    "            tok_key: str = tok.pos_ + \".\" + tok.lemma_.strip().lower()\n",
    "\n",
    "            if tok_key in known_lemma:\n",
    "                tok_idx: int = known_lemma.index(tok_key)\n",
    "\n",
    "                graph.add_edge(\n",
    "                    node_id,\n",
    "                    tok_idx,\n",
    "                    rel = \"COMPOUND_ELEMENT_OF\",\n",
    "                )\n",
    "    else:\n",
    "        node_id: int = known_lemma.index(ent.key)\n",
    "        node: dict = graph.nodes[node_id]\n",
    "        # promote to an Entity, in case the node had been a Lemma\n",
    "        node[\"kind\"] = \"Entity\"\n",
    "        node[\"chunk\"] = ent.chunk_id\n",
    "        node[\"count\"] += 1\n",
    "\n",
    "        # select the more specific label\n",
    "        if \"label\" not in node or node[\"label\"] == \"NP\":\n",
    "          node[\"label\"] = ent.label\n",
    "\n",
    "    ent.node = node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac35293-8fe1-455a-9ab1-27f9302f1bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:23.399417Z",
     "iopub.status.busy": "2024-08-12T20:28:23.399312Z",
     "iopub.status.idle": "2024-08-12T20:28:26.424533Z",
     "shell.execute_reply": "2024-08-12T20:28:26.424226Z",
     "shell.execute_reply.started": "2024-08-12T20:28:23.399405Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ent in span_decoder.values():\n",
    "    if ent.key not in STOP_WORDS:\n",
    "        extract_entity(ent)\n",
    "        ic(ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055708e-23b3-42fd-8fe6-30d40d0eccd5",
   "metadata": {},
   "source": [
    "Report the relations inferred by `GLiREL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaee19b-91b5-4eca-bdcc-15d58c39a975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:26.425296Z",
     "iopub.status.busy": "2024-08-12T20:28:26.425167Z",
     "iopub.status.idle": "2024-08-12T20:28:26.453010Z",
     "shell.execute_reply": "2024-08-12T20:28:26.452613Z",
     "shell.execute_reply.started": "2024-08-12T20:28:26.425284Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relations: typing.List[ dict ] = sorted(\n",
    "    doc._.relations,\n",
    "    key = lambda x: x[\"score\"],\n",
    "    reverse = True,\n",
    ")\n",
    "\n",
    "for item in relations:\n",
    "    src_loc: typing.Tuple[ int ] = tuple(item[\"head_pos\"])\n",
    "    dst_loc: typing.Tuple[ int ] = tuple(item[\"tail_pos\"])\n",
    "    skip_rel: bool = False\n",
    "\n",
    "    if src_loc not in span_decoder:\n",
    "        print(\"MISSING src entity:\", item[\"head_text\"], item[\"head_pos\"])\n",
    "        \n",
    "        src_ent: Entity = make_entity(\n",
    "            doc[ item[\"head_pos\"][0] : item[\"head_pos\"][1] ],\n",
    "            chunk,\n",
    "        )\n",
    "\n",
    "        if src_ent.key in STOP_WORDS:\n",
    "            skip_rel = True\n",
    "        else:\n",
    "            extract_entity(src_ent)\n",
    "\n",
    "    if dst_loc not in span_decoder:\n",
    "        print(\"MISSING dst entity:\", item[\"tail_text\"], item[\"tail_pos\"])\n",
    "\n",
    "        dst_ent: Entity = make_entity(\n",
    "            doc[ item[\"tail_pos\"][0] : item[\"tail_pos\"][1] ],\n",
    "            chunk,\n",
    "        )\n",
    "\n",
    "        if dst_ent.key in STOP_WORDS:\n",
    "            skip_rel = True\n",
    "        else:\n",
    "            extract_entity(dst_ent)\n",
    "\n",
    "    # link the connected nodes\n",
    "    if not skip_rel:\n",
    "        src_ent = span_decoder[src_loc]\n",
    "        dst_ent = span_decoder[dst_loc]\n",
    "\n",
    "        rel: str = item[\"label\"].strip().replace(\" \", \"_\").upper()\n",
    "        prob: float = round(item[\"score\"], 3)\n",
    "\n",
    "        print(f\"{src_ent.text} {src_ent.node} -> {rel} -> {dst_ent.text} {dst_ent.node} | {prob}\")\n",
    "\n",
    "        graph.add_edge(\n",
    "            src_ent.node,\n",
    "            dst_ent.node,\n",
    "            rel = rel,\n",
    "            prob = prob,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305abab-f875-4b74-80ce-36f9619d3e91",
   "metadata": {},
   "source": [
    "Connect the co-occurring entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f3ffd6e-ff44-456f-88ec-560d17a646d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:26.453745Z",
     "iopub.status.busy": "2024-08-12T20:28:26.453607Z",
     "iopub.status.idle": "2024-08-12T20:28:26.457449Z",
     "shell.execute_reply": "2024-08-12T20:28:26.457036Z",
     "shell.execute_reply.started": "2024-08-12T20:28:26.453731Z"
    }
   },
   "outputs": [],
   "source": [
    "ent_map: typing.Dict[ int, typing.Set[ int ]] = defaultdict(set)\n",
    "\n",
    "for ent in span_decoder.values():\n",
    "    if ent.node is not None:\n",
    "        ent_map[ent.sent_id].add(ent.node)    \n",
    "\n",
    "for sent_id, nodes in ent_map.items():\n",
    "    for pair in itertools.combinations(list(nodes), 2):\n",
    "        if not graph.has_edge(*pair):\n",
    "            graph.add_edge(\n",
    "                pair[0],\n",
    "                pair[1],\n",
    "                rel = \"CO_OCCURS_WITH\",\n",
    "                prob = 1.0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef531f80-7ccb-4569-8119-d59e196435f1",
   "metadata": {},
   "source": [
    "Run eigenvalue centrality (i.e., _Personalized PageRank_) to rank the entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e15e1df8-3895-481e-b5e5-1d4148159b28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:26.458261Z",
     "iopub.status.busy": "2024-08-12T20:28:26.458144Z",
     "iopub.status.idle": "2024-08-12T20:28:26.463798Z",
     "shell.execute_reply": "2024-08-12T20:28:26.463516Z",
     "shell.execute_reply.started": "2024-08-12T20:28:26.458247Z"
    }
   },
   "outputs": [],
   "source": [
    "for node, rank in nx.pagerank(graph, alpha = TR_ALPHA, weight = \"count\").items():\n",
    "    graph.nodes[node][\"rank\"] = rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0859353-9b9c-4a29-b7b6-190600751547",
   "metadata": {},
   "source": [
    "Report the top-ranked entities extracted from this text chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bd4df-53f0-4818-ac3f-88e7d24e031c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:26.464470Z",
     "iopub.status.busy": "2024-08-12T20:28:26.464362Z",
     "iopub.status.idle": "2024-08-12T20:28:26.475476Z",
     "shell.execute_reply": "2024-08-12T20:28:26.475218Z",
     "shell.execute_reply.started": "2024-08-12T20:28:26.464456Z"
    }
   },
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.DataFrame([\n",
    "    node_attr\n",
    "    for node, node_attr in graph.nodes(data = True)\n",
    "    if node_attr[\"kind\"] == \"Entity\"\n",
    "]).sort_values(by = [ \"rank\", \"count\" ], ascending = False)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9c670-45cf-4c06-a299-efeeaff63924",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7683b-7470-4860-839a-fb12e70acba2",
   "metadata": {},
   "source": [
    "Use `pyvis` to provide an interactive visualization of both layers of the graph, so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8a259-18b3-47ac-8911-96129684c0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:26.480050Z",
     "iopub.status.busy": "2024-08-12T20:28:26.479864Z",
     "iopub.status.idle": "2024-08-12T20:28:26.508457Z",
     "shell.execute_reply": "2024-08-12T20:28:26.508139Z",
     "shell.execute_reply.started": "2024-08-12T20:28:26.480035Z"
    }
   },
   "outputs": [],
   "source": [
    "pv_net: pyvis.network.Network = pyvis.network.Network(\n",
    "    height = \"750px\",\n",
    "    width = \"100%\",\n",
    "    notebook = True,\n",
    "    cdn_resources = \"remote\",\n",
    ")\n",
    "\n",
    "for node_id, node_attr in graph.nodes(data = True):\n",
    "    if node_attr[\"kind\"] == \"Entity\":\n",
    "        color: str = \"hsl(65, 46%, 58%)\"\n",
    "        size: int = round(200 * node_attr[\"rank\"])\n",
    "    else:\n",
    "        color = \"hsla(72, 10%, 90%, 0.95)\"\n",
    "        size = round(30 * node_attr[\"rank\"])\n",
    "\n",
    "    pv_net.add_node(\n",
    "        node_id,\n",
    "        label = node_attr[\"text\"],\n",
    "        title = node_attr.get(\"label\"),\n",
    "        color = color,\n",
    "        size = size,\n",
    "    )\n",
    "\n",
    "for src_node, dst_node, edge_attr in graph.edges(data = True):\n",
    "    pv_net.add_edge(\n",
    "        src_node,\n",
    "        dst_node,\n",
    "        title = edge_attr.get(\"rel\"),\n",
    "    )\n",
    "\n",
    "pv_net.toggle_physics(True)\n",
    "pv_net.show(\"../data/processed/graphrag_contruct.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be1d4e-8d13-47db-87ca-2b1271e25459",
   "metadata": {},
   "source": [
    "Show a cluster analysis of the _lexical graph_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1333aed0-43b1-46a8-9c38-b1b7e1057798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:26.509066Z",
     "iopub.status.busy": "2024-08-12T20:28:26.508950Z",
     "iopub.status.idle": "2024-08-12T20:28:26.519777Z",
     "shell.execute_reply": "2024-08-12T20:28:26.519162Z",
     "shell.execute_reply.started": "2024-08-12T20:28:26.509053Z"
    }
   },
   "outputs": [],
   "source": [
    "communities: typing.Generator = nx.community.louvain_communities(graph)\n",
    "\n",
    "comm_map: typing.Dict[ int, int ] = {\n",
    "    node_id: i\n",
    "    for i, comm in enumerate(communities)\n",
    "    for node_id in comm\n",
    "}\n",
    "                                                                                                                            \n",
    "xkcd_colors: typing.List[ str ] = list(matplotlib.colors.XKCD_COLORS.values())\n",
    "\n",
    "colors: typing.List[ str ] = [\n",
    "    xkcd_colors[comm_map[n]]\n",
    "    for n in list(graph.nodes())\n",
    "]\n",
    "                                                                                                                                         \n",
    "labels: typing.Dict[ int, str ] = {\n",
    "    node_id: node_attr[\"text\"]\n",
    "    for node_id, node_attr in graph.nodes(data = True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14b7d7-f125-4a94-926e-8f33efaef35e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:26.520505Z",
     "iopub.status.busy": "2024-08-12T20:28:26.520373Z",
     "iopub.status.idle": "2024-08-12T20:28:27.050139Z",
     "shell.execute_reply": "2024-08-12T20:28:27.049779Z",
     "shell.execute_reply.started": "2024-08-12T20:28:26.520488Z"
    }
   },
   "outputs": [],
   "source": [
    "SPRING_DISTANCE: float = 2.5\n",
    "                                                                                                                                     \n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    pos = nx.spring_layout(\n",
    "        graph,\n",
    "        k = SPRING_DISTANCE / len(communities),\n",
    "    ),\n",
    "    labels = labels,\n",
    "    node_color = colors,\n",
    "    edge_color = \"#bbb\",\n",
    "    with_labels = True,\n",
    "    font_size = 8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4e1eb-0f74-4750-94ee-59ec02639d0c",
   "metadata": {},
   "source": [
    "## Tear down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed295918-d7b0-4989-8f28-4bb982ebc4f1",
   "metadata": {},
   "source": [
    "How much did the global data structures grow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8d63e-41c5-4e94-b918-5e435f9d4b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:27.051015Z",
     "iopub.status.busy": "2024-08-12T20:28:27.050801Z",
     "iopub.status.idle": "2024-08-12T20:28:27.100731Z",
     "shell.execute_reply": "2024-08-12T20:28:27.100394Z",
     "shell.execute_reply.started": "2024-08-12T20:28:27.050999Z"
    }
   },
   "outputs": [],
   "source": [
    "ic(len(known_lemma))\n",
    "ic(len(span_decoder))\n",
    "ic(len(graph.nodes()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b6640-1ae4-46bb-944d-6488f138faaf",
   "metadata": {},
   "source": [
    "Stop the profiler and report the performance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17e9f6-7551-4550-9923-4366b93df033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:27.101449Z",
     "iopub.status.busy": "2024-08-12T20:28:27.101320Z",
     "iopub.status.idle": "2024-08-12T20:28:27.442080Z",
     "shell.execute_reply": "2024-08-12T20:28:27.441813Z",
     "shell.execute_reply.started": "2024-08-12T20:28:27.101436Z"
    }
   },
   "outputs": [],
   "source": [
    "profiler.stop()\n",
    "profiler.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5504bb1-e572-4a39-a1c3-d116ffccb2bd",
   "metadata": {},
   "source": [
    "## Quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7923fad-8954-4bb2-a30d-2e74eae4c285",
   "metadata": {},
   "source": [
    "Are there any prounoun lemmas that we need to add to the `STOP_WORDS` list? Until we have a good _coreference_ stage in this workflow, the pronouns are too generic and tend to distort the graph results. NB: compound references are \"contained\" and not a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfd481-1db0-46c6-a3e5-34a86d8d9b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:27.442670Z",
     "iopub.status.busy": "2024-08-12T20:28:27.442586Z",
     "iopub.status.idle": "2024-08-12T20:28:27.444811Z",
     "shell.execute_reply": "2024-08-12T20:28:27.444399Z",
     "shell.execute_reply.started": "2024-08-12T20:28:27.442662Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in known_lemma:\n",
    "    if \"PRON\" in x:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8545e-57c9-4bc8-b9ce-bbf6f8616080",
   "metadata": {},
   "source": [
    "Which nodes should we promote to the next level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570f798-e5a3-4976-8d07-5049af8c307b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:27.445347Z",
     "iopub.status.busy": "2024-08-12T20:28:27.445263Z",
     "iopub.status.idle": "2024-08-12T20:28:27.448316Z",
     "shell.execute_reply": "2024-08-12T20:28:27.448098Z",
     "shell.execute_reply.started": "2024-08-12T20:28:27.445341Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kept_nodes: typing.Set[ int ] = set()\n",
    "\n",
    "for node_id, node_attr in graph.nodes(data = True):\n",
    "    if node_attr[\"kind\"] == \"Entity\":\n",
    "        print(node_id, node_attr[\"key\"], node_attr[\"rank\"], node_attr[\"label\"], node_attr[\"text\"], node_attr[\"chunk\"])\n",
    "        kept_nodes.add(node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca39ea-565f-4325-98fa-712208ab255d",
   "metadata": {},
   "source": [
    "Which edges should we promote to the next level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db93959-90b7-4967-b0c9-f7bca8b3fc23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T20:28:27.448714Z",
     "iopub.status.busy": "2024-08-12T20:28:27.448633Z",
     "iopub.status.idle": "2024-08-12T20:28:27.452496Z",
     "shell.execute_reply": "2024-08-12T20:28:27.452289Z",
     "shell.execute_reply.started": "2024-08-12T20:28:27.448708Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skip_rel: typing.Set[ str ] = set([ \"FOLLOWS_LEXICALLY\", \"COMPOUND_ELEMENT_OF\" ])\n",
    "\n",
    "for src_id, dst_id, edge_attr in graph.edges(data = True):\n",
    "    if src_id in kept_nodes and dst_id in kept_nodes:\n",
    "        rel: str = edge_attr[\"rel\"]\n",
    "\n",
    "        if rel not in skip_rel:\n",
    "            print(src_id, dst_id, rel, edge_attr[\"prob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aede50a-b14d-4c9b-9bdd-1efd2262f66f",
   "metadata": {},
   "source": [
    "## CITATION:  inspired by Poco Nathan's presentation to GraphGeeks.org on 2024-08-14\n",
    "- https://github.com/DerwenAI/strwythura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0781bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
