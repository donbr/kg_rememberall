{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç LightRAG Validation with Arize Phoenix\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook provides one approach for validating and monitoring LightRAG's interaction with LLMs and embedding models -- leveraging [Arize Phoenix](https://docs.arize.com/phoenix/tracing/llm-traces-1) it provides insight into what is a very complex data ingestion pipeline.\n",
    "\n",
    "It will also make the concepts covered in the LightRAG paper more tangible.\n",
    "\n",
    "### Purpose\n",
    "- **System Monitoring**: Validate LightRAG's integration with telemetry pipelines to ensure robust tracking of model inference and embedding use.\n",
    "- **Performance Tuning**: Identify bottlenecks and optimize configurations using insights from telemetry data.\n",
    "- **Proactive Debugging**: Quickly detect and resolve anomalies through real-time analysis.\n",
    "\n",
    "### Key Features\n",
    "- **Dockerized Deployment**: Simplifies setup with preconfigured Docker containers for Arize Phoenix.\n",
    "- **Telemetry Integration**: Supports integration with external systems through use of OpenTelemetry standard to provide detailed system traces.\n",
    "- **Customizable Dashboards**: Enables interactive exploration of model metrics and error logs.\n",
    "\n",
    "### Usage Instructions\n",
    "1. **Setup**: \n",
    "    - Install required dependencies:\n",
    "      ```bash\n",
    "      pip install arize-phoenix-otel\n",
    "      ```\n",
    "    - Run the Docker container for Arize Phoenix:\n",
    "      ```bash\n",
    "      docker run -p 6006:6006 -p 4317:4317 --rm arizephoenix/phoenix:latest\n",
    "      ```\n",
    "\n",
    "2. **Execute the Notebook**: Follow the provided steps in the notebook to validate your LightRAG setup against telemetry data.\n",
    "\n",
    "3. **Explore Metrics**:\n",
    "    - Access the Phoenix UI at [http://localhost:6006](http://localhost:6006).\n",
    "    - Analyze detailed traces, latencies, and throughput metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ipywidgets lightrag-hku openai aioboto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define configuration constants\n",
    "DATA_DIR = Path(\"../data\")  # Base data directory\n",
    "INTERIM_DIR = DATA_DIR / \"interim\"  # Interim data directory\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"  # Processed data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define URL and local file path\n",
    "src_file_url = \"https://raw.githubusercontent.com/donbr/kg_rememberall/refs/heads/main/references/winston_churchill_we_shall_fight_speech_june_1940.txt\"\n",
    "file_name = src_file_url.split(\"/\")[-1].replace(\".\", \"_\").lower()\n",
    "\n",
    "WORKING_DIR = INTERIM_DIR / file_name\n",
    "\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and save the file\n",
    "response = requests.get(src_file_url)\n",
    "response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "local_file_path = WORKING_DIR / f\"{file_name}.txt\"\n",
    "local_file_path.write_text(response.text)\n",
    "\n",
    "# Define file paths\n",
    "GRAPHML_FILE = WORKING_DIR / \"graph_chunk_entity_relation.graphml\"\n",
    "PYVIS_HTML_FILE = PROCESSED_DIR / f\"{file_name}.html\"\n",
    "PYVIS_HTML_FILE2 = PROCESSED_DIR / f\"{file_name}2.html\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arize Phoenix\n",
    "\n",
    "- UI endpoint:  http://localhost:6006\n",
    "- NOTE:  the Docker container will be removed when you shut down the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['docker', 'run', '-p', '6006:6006', '-p', '4...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ‚Äç‚ôÄÔ∏è‚Äç‚û°Ô∏è Running migrations on the database.\n",
      "---------------------------\n",
      "2025-01-20 04:26:29,002 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-01-20 04:26:29,002 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"alembic_version\")\n",
      "2025-01-20 04:26:29,002 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"alembic_version\")\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"alembic_version\")\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"alembic_version\")\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE alembic_version (\n",
      "\tversion_num VARCHAR(32) NOT NULL, \n",
      "\tCONSTRAINT alembic_version_pkc PRIMARY KEY (version_num)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,003 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,012 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE projects (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tgradient_start_color VARCHAR DEFAULT '#5bdbff' NOT NULL, \n",
      "\tgradient_end_color VARCHAR DEFAULT '#1c76fc' NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_projects PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_projects_name UNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,012 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:26:29,015 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE traces (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tproject_rowid INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_traces PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_traces_project_rowid_projects FOREIGN KEY(project_rowid) REFERENCES projects (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_traces_trace_id UNIQUE (trace_id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,015 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,018 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_rowid ON traces (project_rowid)\n",
      "2025-01-20 04:26:29,018 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,020 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_start_time ON traces (start_time)\n",
      "2025-01-20 04:26:29,021 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:26:29,024 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE spans (\n",
      "\tid INTEGER NOT NULL, \n",
      "\ttrace_rowid INTEGER NOT NULL, \n",
      "\tspan_id VARCHAR NOT NULL, \n",
      "\tparent_id VARCHAR, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tspan_kind VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tattributes JSONB NOT NULL, \n",
      "\tevents JSONB NOT NULL, \n",
      "\tstatus_code VARCHAR DEFAULT 'UNSET' NOT NULL CONSTRAINT \"ck_spans_`valid_status`\" CHECK (status_code IN ('OK', 'ERROR', 'UNSET')), \n",
      "\tstatus_message VARCHAR NOT NULL, \n",
      "\tcumulative_error_count INTEGER NOT NULL, \n",
      "\tcumulative_llm_token_count_prompt INTEGER NOT NULL, \n",
      "\tcumulative_llm_token_count_completion INTEGER NOT NULL, \n",
      "\tCONSTRAINT pk_spans PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_spans_trace_rowid_traces FOREIGN KEY(trace_rowid) REFERENCES traces (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_spans_span_id UNIQUE (span_id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,024 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,026 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_start_time ON spans (start_time)\n",
      "2025-01-20 04:26:29,027 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,029 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_trace_rowid ON spans (trace_rowid)\n",
      "2025-01-20 04:26:29,029 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,031 INFO sqlalchemy.engine.Engine CREATE INDEX ix_spans_parent_id ON spans (parent_id)\n",
      "2025-01-20 04:26:29,031 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,034 INFO sqlalchemy.engine.Engine CREATE INDEX ix_latency ON spans ((end_time - start_time))\n",
      "2025-01-20 04:26:29,034 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,036 INFO sqlalchemy.engine.Engine CREATE INDEX ix_cumulative_llm_token_count_total ON spans ((cumulative_llm_token_count_prompt + cumulative_llm_token_count_completion))\n",
      "2025-01-20 04:26:29,036 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,040 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE span_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_span_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_span_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_span_annotations_name_span_rowid UNIQUE (name, span_rowid), \n",
      "\tCONSTRAINT fk_span_annotations_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,040 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,043 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_span_rowid ON span_annotations (span_rowid)\n",
      "2025-01-20 04:26:29,043 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,045 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_score ON span_annotations (score)\n",
      "2025-01-20 04:26:29,045 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,047 INFO sqlalchemy.engine.Engine CREATE INDEX ix_span_annotations_label ON span_annotations (label)\n",
      "2025-01-20 04:26:29,047 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,051 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE trace_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\ttrace_rowid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_trace_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_trace_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_trace_annotations_name_trace_rowid UNIQUE (name, trace_rowid), \n",
      "\tCONSTRAINT fk_trace_annotations_trace_rowid_traces FOREIGN KEY(trace_rowid) REFERENCES traces (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,051 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,053 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_score ON trace_annotations (score)\n",
      "2025-01-20 04:26:29,053 INFO sqlalchemy.engine.Engine [no key 0.00009s] ()\n",
      "2025-01-20 04:26:29,058 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_trace_rowid ON trace_annotations (trace_rowid)\n",
      "2025-01-20 04:26:29,058 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,060 INFO sqlalchemy.engine.Engine CREATE INDEX ix_trace_annotations_label ON trace_annotations (label)\n",
      "2025-01-20 04:26:29,060 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,064 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE document_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER NOT NULL, \n",
      "\tdocument_position INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_document_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'HUMAN')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_document_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_document_annotations_name_span_rowid_document_position UNIQUE (name, span_rowid, document_position), \n",
      "\tCONSTRAINT fk_document_annotations_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,064 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,067 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_label ON document_annotations (label)\n",
      "2025-01-20 04:26:29,067 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,069 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_score ON document_annotations (score)\n",
      "2025-01-20 04:26:29,069 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,072 INFO sqlalchemy.engine.Engine CREATE INDEX ix_document_annotations_span_rowid ON document_annotations (span_rowid)\n",
      "2025-01-20 04:26:29,072 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,075 INFO sqlalchemy.engine.Engine INSERT INTO projects (name, description) VALUES (?, ?)\n",
      "2025-01-20 04:26:29,075 INFO sqlalchemy.engine.Engine [generated in 0.00010s] ('default', 'Default project')\n",
      "2025-01-20 04:26:29,075 INFO sqlalchemy.engine.Engine INSERT INTO alembic_version (version_num) VALUES ('cf03bd6bae1d') RETURNING version_num\n",
      "2025-01-20 04:26:29,075 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-20 04:26:29,076 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE datasets (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_datasets PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_datasets_name UNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,076 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,077 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_versions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_versions PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_dataset_versions_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,077 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,077 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_versions_dataset_id ON dataset_versions (dataset_id)\n",
      "2025-01-20 04:26:29,077 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,079 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_examples (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tspan_rowid INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_examples PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_dataset_examples_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_dataset_examples_span_rowid_spans FOREIGN KEY(span_rowid) REFERENCES spans (id) ON DELETE SET NULL\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,079 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,079 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_examples_dataset_id ON dataset_examples (dataset_id)\n",
      "2025-01-20 04:26:29,079 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,079 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_examples_span_rowid ON dataset_examples (span_rowid)\n",
      "2025-01-20 04:26:29,079 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,080 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE dataset_example_revisions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_example_id INTEGER NOT NULL, \n",
      "\tdataset_version_id INTEGER NOT NULL, \n",
      "\tinput JSONB NOT NULL, \n",
      "\toutput JSONB NOT NULL, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\trevision_kind VARCHAR NOT NULL CONSTRAINT \"ck_dataset_example_revisions_`valid_revision_kind`\" CHECK (revision_kind IN ('CREATE', 'PATCH', 'DELETE')), \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_dataset_example_revisions PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_dataset_example_revisions_dataset_example_id_dataset_version_id UNIQUE (dataset_example_id, dataset_version_id), \n",
      "\tCONSTRAINT fk_dataset_example_revisions_dataset_example_id_dataset_examples FOREIGN KEY(dataset_example_id) REFERENCES dataset_examples (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_dataset_example_revisions_dataset_version_id_dataset_versions FOREIGN KEY(dataset_version_id) REFERENCES dataset_versions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,080 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,081 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_example_revisions_dataset_example_id ON dataset_example_revisions (dataset_example_id)\n",
      "2025-01-20 04:26:29,081 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,081 INFO sqlalchemy.engine.Engine CREATE INDEX ix_dataset_example_revisions_dataset_version_id ON dataset_example_revisions (dataset_version_id)\n",
      "2025-01-20 04:26:29,081 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiments (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tdataset_id INTEGER NOT NULL, \n",
      "\tdataset_version_id INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\trepetitions INTEGER NOT NULL, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tproject_name VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT pk_experiments PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_experiments_dataset_id_datasets FOREIGN KEY(dataset_id) REFERENCES datasets (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_experiments_dataset_version_id_dataset_versions FOREIGN KEY(dataset_version_id) REFERENCES dataset_versions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_dataset_id ON experiments (dataset_id)\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_dataset_version_id ON experiments (dataset_version_id)\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiments_project_name ON experiments (project_name)\n",
      "2025-01-20 04:26:29,082 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,083 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiment_runs (\n",
      "\tid INTEGER NOT NULL, \n",
      "\texperiment_id INTEGER NOT NULL, \n",
      "\tdataset_example_id INTEGER NOT NULL, \n",
      "\trepetition_number INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR, \n",
      "\toutput JSONB NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tprompt_token_count INTEGER, \n",
      "\tcompletion_token_count INTEGER, \n",
      "\terror VARCHAR, \n",
      "\tCONSTRAINT pk_experiment_runs PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_experiment_runs_experiment_id_dataset_example_id_repetition_number UNIQUE (experiment_id, dataset_example_id, repetition_number), \n",
      "\tCONSTRAINT fk_experiment_runs_experiment_id_experiments FOREIGN KEY(experiment_id) REFERENCES experiments (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_experiment_runs_dataset_example_id_dataset_examples FOREIGN KEY(dataset_example_id) REFERENCES dataset_examples (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,083 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,083 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_runs_dataset_example_id ON experiment_runs (dataset_example_id)\n",
      "2025-01-20 04:26:29,084 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,084 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_runs_experiment_id ON experiment_runs (experiment_id)\n",
      "2025-01-20 04:26:29,084 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,085 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE experiment_run_annotations (\n",
      "\tid INTEGER NOT NULL, \n",
      "\texperiment_run_id INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tannotator_kind VARCHAR NOT NULL CONSTRAINT \"ck_experiment_run_annotations_`valid_annotator_kind`\" CHECK (annotator_kind IN ('LLM', 'CODE', 'HUMAN')), \n",
      "\tlabel VARCHAR, \n",
      "\tscore FLOAT, \n",
      "\texplanation VARCHAR, \n",
      "\ttrace_id VARCHAR, \n",
      "\terror VARCHAR, \n",
      "\tmetadata JSONB NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_experiment_run_annotations PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_experiment_run_annotations_experiment_run_id_name UNIQUE (experiment_run_id, name), \n",
      "\tCONSTRAINT fk_experiment_run_annotations_experiment_run_id_experiment_runs FOREIGN KEY(experiment_run_id) REFERENCES experiment_runs (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,085 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,085 INFO sqlalchemy.engine.Engine CREATE INDEX ix_experiment_run_annotations_experiment_run_id ON experiment_run_annotations (experiment_run_id)\n",
      "2025-01-20 04:26:29,085 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,086 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='10460e46d750' WHERE alembic_version.version_num = 'cf03bd6bae1d'\n",
      "2025-01-20 04:26:29,086 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-20 04:26:29,086 INFO sqlalchemy.engine.Engine ALTER TABLE spans ADD COLUMN llm_token_count_prompt INTEGER\n",
      "2025-01-20 04:26:29,086 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,086 INFO sqlalchemy.engine.Engine ALTER TABLE spans ADD COLUMN llm_token_count_completion INTEGER\n",
      "2025-01-20 04:26:29,086 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,087 INFO sqlalchemy.engine.Engine UPDATE spans SET llm_token_count_prompt=(JSON_EXTRACT(spans.attributes, ?)), llm_token_count_completion=(JSON_EXTRACT(spans.attributes, ?))\n",
      "2025-01-20 04:26:29,087 INFO sqlalchemy.engine.Engine [generated in 0.00012s] ('$.\"llm\".\"token_count\".\"prompt\"', '$.\"llm\".\"token_count\".\"completion\"')\n",
      "2025-01-20 04:26:29,088 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='3be8647b87d8' WHERE alembic_version.version_num = '10460e46d750'\n",
      "2025-01-20 04:26:29,088 INFO sqlalchemy.engine.Engine [generated in 0.00008s] ()\n",
      "2025-01-20 04:26:29,088 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE user_roles (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tCONSTRAINT pk_user_roles PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,088 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,088 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_user_roles_name ON user_roles (name)\n",
      "2025-01-20 04:26:29,088 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,089 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE users (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_role_id INTEGER NOT NULL, \n",
      "\tusername VARCHAR NOT NULL, \n",
      "\temail VARCHAR NOT NULL, \n",
      "\tprofile_picture_url VARCHAR, \n",
      "\tpassword_hash BLOB, \n",
      "\tpassword_salt BLOB, \n",
      "\treset_password BOOLEAN NOT NULL, \n",
      "\toauth2_client_id VARCHAR, \n",
      "\toauth2_user_id VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tupdated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\tCONSTRAINT \"ck_users_`password_hash_and_salt`\" CHECK ((password_hash IS NULL) = (password_salt IS NULL)), \n",
      "\tCONSTRAINT \"ck_users_`oauth2_client_id_and_user_id`\" CHECK ((oauth2_client_id IS NULL) = (oauth2_user_id IS NULL)), \n",
      "\tCONSTRAINT \"ck_users_`exactly_one_auth_method`\" CHECK ((password_hash IS NULL) != (oauth2_client_id IS NULL)), \n",
      "\tCONSTRAINT uq_users_oauth2_client_id_oauth2_user_id UNIQUE (oauth2_client_id, oauth2_user_id), \n",
      "\tCONSTRAINT fk_users_user_role_id_user_roles FOREIGN KEY(user_role_id) REFERENCES user_roles (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,089 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_oauth2_client_id ON users (oauth2_client_id)\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_users_email ON users (email)\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_user_role_id ON users (user_role_id)\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine CREATE INDEX ix_users_oauth2_user_id ON users (oauth2_user_id)\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_users_username ON users (username)\n",
      "2025-01-20 04:26:29,090 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,091 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE password_reset_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT fk_password_reset_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,091 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,091 INFO sqlalchemy.engine.Engine CREATE INDEX ix_password_reset_tokens_expires_at ON password_reset_tokens (expires_at)\n",
      "2025-01-20 04:26:29,091 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,092 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_password_reset_tokens_user_id ON password_reset_tokens (user_id)\n",
      "2025-01-20 04:26:29,092 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,092 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE refresh_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT fk_refresh_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,092 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,093 INFO sqlalchemy.engine.Engine CREATE INDEX ix_refresh_tokens_user_id ON refresh_tokens (user_id)\n",
      "2025-01-20 04:26:29,093 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,093 INFO sqlalchemy.engine.Engine CREATE INDEX ix_refresh_tokens_expires_at ON refresh_tokens (expires_at)\n",
      "2025-01-20 04:26:29,093 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE access_tokens (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP NOT NULL, \n",
      "\trefresh_token_id INTEGER, \n",
      "\tCONSTRAINT fk_access_tokens_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT fk_access_tokens_refresh_token_id_refresh_tokens FOREIGN KEY(refresh_token_id) REFERENCES refresh_tokens (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine CREATE INDEX ix_access_tokens_user_id ON access_tokens (user_id)\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine CREATE INDEX ix_access_tokens_expires_at ON access_tokens (expires_at)\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX ix_access_tokens_refresh_token_id ON access_tokens (refresh_token_id)\n",
      "2025-01-20 04:26:29,094 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,095 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE api_keys (\n",
      "\tid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \n",
      "\tuser_id INTEGER, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tdescription VARCHAR, \n",
      "\tcreated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP) NOT NULL, \n",
      "\texpires_at TIMESTAMP, \n",
      "\tCONSTRAINT fk_api_keys_user_id_users FOREIGN KEY(user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,095 INFO sqlalchemy.engine.Engine [no key 0.00007s] ()\n",
      "2025-01-20 04:26:29,095 INFO sqlalchemy.engine.Engine CREATE INDEX ix_api_keys_expires_at ON api_keys (expires_at)\n",
      "2025-01-20 04:26:29,095 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,096 INFO sqlalchemy.engine.Engine CREATE INDEX ix_api_keys_user_id ON api_keys (user_id)\n",
      "2025-01-20 04:26:29,096 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,096 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='cd164e83824f' WHERE alembic_version.version_num = '3be8647b87d8'\n",
      "2025-01-20 04:26:29,096 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-20 04:26:29,097 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE project_sessions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tsession_id VARCHAR NOT NULL, \n",
      "\tproject_id INTEGER NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tCONSTRAINT pk_project_sessions PRIMARY KEY (id), \n",
      "\tCONSTRAINT uq_project_sessions_session_id UNIQUE (session_id), \n",
      "\tCONSTRAINT fk_project_sessions_project_id_projects FOREIGN KEY(project_id) REFERENCES projects (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,097 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,097 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_project_id ON project_sessions (project_id)\n",
      "2025-01-20 04:26:29,097 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,097 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_start_time ON project_sessions (start_time)\n",
      "2025-01-20 04:26:29,097 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,098 INFO sqlalchemy.engine.Engine CREATE INDEX ix_project_sessions_end_time ON project_sessions (end_time)\n",
      "2025-01-20 04:26:29,098 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,098 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"traces\")\n",
      "2025-01-20 04:26:29,098 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,098 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:26:29,099 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-20 04:26:29,099 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"traces\")\n",
      "2025-01-20 04:26:29,099 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,099 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:26:29,099 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-20 04:26:29,100 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"traces\")\n",
      "2025-01-20 04:26:29,100 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,100 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_start_time\")\n",
      "2025-01-20 04:26:29,100 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,100 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_project_rowid\")\n",
      "2025-01-20 04:26:29,100 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"traces\")\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_start_time\")\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"ix_traces_project_rowid\")\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"sqlite_autoindex_traces_1\")\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:26:29,101 INFO sqlalchemy.engine.Engine [raw sql] ('traces',)\n",
      "2025-01-20 04:26:29,102 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"projects\")\n",
      "2025-01-20 04:26:29,102 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,102 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:26:29,102 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-20 04:26:29,102 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"projects\")\n",
      "2025-01-20 04:26:29,102 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine PRAGMA temp.foreign_key_list(\"projects\")\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"projects\")\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"projects\")\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"projects\")\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine PRAGMA main.index_info(\"sqlite_autoindex_projects_1\")\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2025-01-20 04:26:29,103 INFO sqlalchemy.engine.Engine [raw sql] ('projects',)\n",
      "2025-01-20 04:26:29,105 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE _alembic_tmp_traces (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tproject_rowid INTEGER NOT NULL, \n",
      "\ttrace_id VARCHAR NOT NULL, \n",
      "\tstart_time TIMESTAMP NOT NULL, \n",
      "\tend_time TIMESTAMP NOT NULL, \n",
      "\tproject_session_rowid INTEGER, \n",
      "\tCONSTRAINT pk_traces PRIMARY KEY (id), \n",
      "\tCONSTRAINT fk_traces_project_rowid_projects FOREIGN KEY(project_rowid) REFERENCES projects (id) ON DELETE CASCADE, \n",
      "\tCONSTRAINT uq_traces_trace_id UNIQUE (trace_id), \n",
      "\tCONSTRAINT fk_traces_project_session_rowid_project_sessions FOREIGN KEY(project_session_rowid) REFERENCES project_sessions (id) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "\n",
      "2025-01-20 04:26:29,105 INFO sqlalchemy.engine.Engine [no key 0.00008s] ()\n",
      "2025-01-20 04:26:29,106 INFO sqlalchemy.engine.Engine INSERT INTO _alembic_tmp_traces (id, project_rowid, trace_id, start_time, end_time) SELECT traces.id, traces.project_rowid, traces.trace_id, traces.start_time, traces.end_time \n",
      "FROM traces\n",
      "2025-01-20 04:26:29,106 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-20 04:26:29,106 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE traces\n",
      "2025-01-20 04:26:29,106 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,106 INFO sqlalchemy.engine.Engine ALTER TABLE _alembic_tmp_traces RENAME TO traces\n",
      "2025-01-20 04:26:29,106 INFO sqlalchemy.engine.Engine [no key 0.00005s] ()\n",
      "2025-01-20 04:26:29,107 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_start_time ON traces (start_time)\n",
      "2025-01-20 04:26:29,107 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,107 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_rowid ON traces (project_rowid)\n",
      "2025-01-20 04:26:29,107 INFO sqlalchemy.engine.Engine [no key 0.00004s] ()\n",
      "2025-01-20 04:26:29,108 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traces_project_session_rowid ON traces (project_session_rowid)\n",
      "2025-01-20 04:26:29,108 INFO sqlalchemy.engine.Engine [no key 0.00006s] ()\n",
      "2025-01-20 04:26:29,108 INFO sqlalchemy.engine.Engine UPDATE alembic_version SET version_num='4ded9e43755f' WHERE alembic_version.version_num = 'cd164e83824f'\n",
      "2025-01-20 04:26:29,108 INFO sqlalchemy.engine.Engine [generated in 0.00009s] ()\n",
      "2025-01-20 04:26:29,108 INFO sqlalchemy.engine.Engine COMMIT\n",
      "---------------------------\n",
      "‚úÖ Migrations completed in 0.111 seconds.\n",
      "\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ïî‚ïù\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïó\n",
      "‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù v7.7.1\n",
      "\n",
      "|\n",
      "|  üåé Join our Community üåé\n",
      "|  https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\n",
      "|\n",
      "|  ‚≠êÔ∏è Leave us a Star ‚≠êÔ∏è\n",
      "|  https://github.com/Arize-ai/phoenix\n",
      "|\n",
      "|  üìö Documentation üìö\n",
      "|  https://docs.arize.com/phoenix\n",
      "|\n",
      "|  üöÄ Phoenix Server üöÄ\n",
      "|  Phoenix UI: http://0.0.0.0:6006\n",
      "|  Authentication: False\n",
      "|  Websockets: True\n",
      "|  Log traces:\n",
      "|    - gRPC: http://0.0.0.0:4317\n",
      "|    - HTTP: http://0.0.0.0:6006/v1/traces\n",
      "|  Storage: sqlite:////root/.phoenix/phoenix.db\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:6006 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# for more information refer to https://docs.arize.com/phoenix/tracing/integrations-tracing/autogen-support#docker\n",
    "# !docker run -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Run the Docker container without interactive mode\n",
    "subprocess.Popen([\n",
    "    \"docker\", \"run\", \"-p\", \"6006:6006\", \"-p\", \"4317:4317\",\n",
    "    \"--rm\", \"arizephoenix/phoenix:latest\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arize Phoenix:  setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q arize-phoenix-otel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: lightrag-openai\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'authorization': '****', 'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "# defaults to endpoint=\"http://localhost:4317\"\n",
    "tracer_provider = register(\n",
    "  project_name=\"lightrag-openai\", # Default is 'default'\n",
    "  endpoint=\"http://localhost:4317\",  # Sends traces using gRPC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## install python telemetry and openai library requirements\n",
    "%pip install -q openinference-instrumentation-openai openai 'httpx<0.28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Use Case\n",
    "\n",
    "Monitor LightRAG‚Äôs real-time LLM and embedding model usage\n",
    "- performance and response latencies\n",
    "- model behavior and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the Graph\n",
    "\n",
    "- Initialize LightRAG and OpenAI connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install Ollama as LightRAG requires it\n",
    "%pip install -q ollama tiktoken nano_vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: ../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt\n",
      "INFO:lightrag:Load KV llm_response_cache with 0 data\n",
      "INFO:lightrag:Load KV full_docs with 0 data\n",
      "INFO:lightrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../data/interim/winston_churchill_we_shall_fight_speech_june_1940_txt/vdb_chunks.json'} 0 data\n",
      "INFO:lightrag:Loaded document status storage with 0 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm import gpt_4o_mini_complete\n",
    "import nano_vectordb\n",
    "\n",
    "#########\n",
    "# Uncomment the below two lines if running in a jupyter notebook to handle the async nature of rag.insert()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "#########\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model\n",
    "    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Processing 1 new unique documents\n",
      "Processing batch 1:   0%|          | 0/1 [00:00<?, ?it/s]INFO:lightrag:Inserting 5 vectors to chunks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.36s/batch]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†ô Processed 1 chunks, 5 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†π Processed 2 chunks, 22 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†∏ Processed 3 chunks, 49 entities(duplicated), 21 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†º Processed 4 chunks, 67 entities(duplicated), 32 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚†¥ Processed 5 chunks, 101 entities(duplicated), 38 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:27<00:00,  5.53s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91/91 [00:00<00:00, 27602.09entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:00<00:00, 12717.51relationship/s]\n",
      "INFO:lightrag:Inserting 91 vectors to entities\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.89batch/s]\n",
      "INFO:lightrag:Inserting 36 vectors to relationships\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19batch/s]\n",
      "INFO:lightrag:Writing graph with 93 nodes, 36 edges\n",
      "Processing batch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:34<00:00, 34.19s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(local_file_path) as f:\n",
    "    rag.insert(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## APPROACH 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:kw_prompt result:\n",
      "INFO:lightrag:Using hybrid mode for query processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"high_level_keywords\": [\"King Leopold\", \"Evacuation of Dunkirk\", \"Historical role\"],\n",
      "  \"low_level_keywords\": [\"World War II\", \"British Expeditionary Force\", \"French forces\", \"Military strategy\", \"Belgium\"]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Local query uses 60 entites, 34 relations, 3 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Global query uses 45 entites, 35 relations, 3 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### King Leopold's Influence and Decisions\n",
      "\n",
      "King Leopold of Belgium played a significant role during the events leading up to the evacuation of Dunkirk. His decisions directly influenced the fate of the Belgian Army and impacted military strategies for the Allied forces as they faced the German invasion during World War II. Initially, King Leopold sought assistance from the Allies when Belgium was invaded, which led to the involvement of British and French troops in an effort to defend Belgium. \n",
      "\n",
      "However, as the German forces advanced and the situation became increasingly dire, King Leopold made a critical decision that would have far-reaching implications. He unilaterally decided to surrender the Belgian Army to the Germans without prior consultation or the advice of his ministers. This act exposed the Allies' flank and left the British and French forces in a vulnerable position, impacting their ability to effectively retreat.\n",
      "\n",
      "### Consequences of the Surrender\n",
      "\n",
      "The surrender of the Belgian Army meant that the British Army had to urgently cover a lengthy flank along the coast, approximately 30 miles long, to prevent being cut off from retreat to Dunkirk. The loss of coordination between the British forces and the remaining elements of the French army further complicated the evacuation efforts. Despite King Leopold's call for assistance from the Allies, his move to surrender significantly weakened the collective defensive capability against the advancing German forces.\n",
      "\n",
      "### The Evacuation of Dunkirk\n",
      "\n",
      "As the Allied troops retreated toward Dunkirk, King Leopold's earlier surrender had already compromised their strategic position. As a result, during the critical days of the evacuation, the remaining Belgian forces were caught in a precarious situation, while British and French troops fought fiercely to maintain a line of retreat. Ultimately, the Royal Navy, with the help of merchant seamen, managed to evacuate a significant number of troops from Dunkirk, but this rescue operation was tempered by the broader context of military disaster across Belgium and France, aspects that King Leopold's earlier decision contributed to.\n",
      "\n",
      "In conclusion, King Leopold's actions during the onset of the German invasion, particularly his surrender of the Belgian Army, had profound implications for the Dunkirk evacuation and illustrated the complex interplay of leadership and military strategy during this tumultuous period.\n"
     ]
    }
   ],
   "source": [
    "# Perform hybrid search\n",
    "print(\"\\n## APPROACH 4\\n\")\n",
    "print(rag.query(\"What role did King Leopold play during the evacuation of Dunkirk?\", param=QueryParam(mode=\"hybrid\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Graph\n",
    "\n",
    "- graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def create_interactive_visualization(graphml_file, output_file):\n",
    "    # Load the GraphML file\n",
    "    G = nx.read_graphml(graphml_file)\n",
    "    \n",
    "    # Create Pyvis network\n",
    "    net = Network(height='900px', width='100%', bgcolor='#ffffff', \n",
    "                 font_color='black', notebook=False)\n",
    "    \n",
    "    # Define color scheme for entity types\n",
    "    entity_colors = {\n",
    "        'PERSON': '#e41a1c',        # Bright red\n",
    "        'ORGANIZATION': '#377eb8',   # Blue\n",
    "        'GEO': '#4daf4a',           # Green\n",
    "        'EVENT': '#984ea3',         # Purple\n",
    "        'CONCEPT': '#ff7f00',       # Orange\n",
    "        'TECHNOLOGY': '#a65628',     # Brown\n",
    "        'CATEGORY': '#f781bf',      # Pink\n",
    "        'NUMBER': '#999999',        # Gray\n",
    "        'UNKNOWN': '#808080'        # Dark Gray\n",
    "    }\n",
    "    \n",
    "    # Add nodes with colors before adding edges\n",
    "    for node_id, node_data in G.nodes(data=True):\n",
    "        # Get entity type (removing quotes if present)\n",
    "        entity_type = node_data.get('entity_type', 'UNKNOWN').replace('\"', '')\n",
    "        color = entity_colors.get(entity_type, '#808080')\n",
    "        \n",
    "        # Create hover text\n",
    "        hover_info = f\"\"\"\n",
    "        Entity: {node_id}\n",
    "        Type: {entity_type}\n",
    "        Description: {node_data.get('description', 'N/A')}\n",
    "        Source ID: {node_data.get('source_id', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add node with properties\n",
    "        net.add_node(node_id, \n",
    "                    title=hover_info,\n",
    "                    color=color,\n",
    "                    size=30)\n",
    "\n",
    "    # Add edges\n",
    "    for source, target, edge_data in G.edges(data=True):\n",
    "        weight = edge_data.get('weight', 1)\n",
    "        description = edge_data.get('description', '')\n",
    "        \n",
    "        hover_info = f\"\"\"\n",
    "        Weight: {weight}\n",
    "        Description: {description}\n",
    "        Keywords: {edge_data.get('keywords', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        net.add_edge(source, target,\n",
    "                    title=hover_info,\n",
    "                    width=float(weight),\n",
    "                    color={'color': '#666666', 'highlight': '#ff0000'})\n",
    "\n",
    "    # Rest of your physics and legend code remains the same\n",
    "    physics_options = {\n",
    "        \"physics\": {\n",
    "            \"forceAtlas2Based\": {\n",
    "                \"gravitationalConstant\": -100,\n",
    "                \"centralGravity\": 0.01,\n",
    "                \"springLength\": 200,\n",
    "                \"springConstant\": 0.08,\n",
    "                \"damping\": 0.4,\n",
    "                \"avoidOverlap\": 1\n",
    "            },\n",
    "            \"solver\": \"forceAtlas2Based\",\n",
    "            \"stabilization\": {\n",
    "                \"enabled\": True,\n",
    "                \"iterations\": 1000,\n",
    "                \"updateInterval\": 25\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    net.set_options(json.dumps(physics_options))\n",
    "    \n",
    "    # Save and add legend\n",
    "    net.write_html(output_file)\n",
    "    \n",
    "    # Add legend HTML\n",
    "    legend_html = \"\"\"\n",
    "    <div style=\"position: absolute; top: 10px; left: 10px; background-color: rgba(255, 255, 255, 0.9); \n",
    "                padding: 10px; border-radius: 5px; border: 1px solid #ccc;\">\n",
    "        <h3>Entity Types</h3>\n",
    "        <ul style=\"list-style-type: none; padding: 0;\">\n",
    "    \"\"\"\n",
    "    \n",
    "    for entity_type, color in entity_colors.items():\n",
    "        legend_html += f\"\"\"\n",
    "            <li style=\"margin: 5px 0;\">\n",
    "                <span style=\"display: inline-block; width: 20px; height: 20px; \n",
    "                           background-color: {color}; border-radius: 50%; margin-right: 5px;\"></span>\n",
    "                {entity_type}\n",
    "            </li>\n",
    "        \"\"\"\n",
    "    \n",
    "    legend_html += \"\"\"\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    content = content.replace('</body>', f'{legend_html}</body>')\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Visualization\n",
    "create_interactive_visualization(GRAPHML_FILE, str(PYVIS_HTML_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Telemetry data\n",
    "\n",
    "- Access the Arize Phoenix UI at [http://localhost:6006](http://localhost:6006)\n",
    "- both LLM inference and embedding telemetry information is captured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
